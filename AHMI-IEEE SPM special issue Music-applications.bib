Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@inproceedings{Bongers1994,
abstract = {Since the first modular synthesizers, it became possible (for the first time in history) to separate the interface from the actual sound source. It makes sense to try to design new interfaces, new instruments. unbounded by the sound source. Due to this separation. the connection between the sound and thefeel of the instrument was lost. Our goal is to restore the relationship, and, moreover, to make this haptic feedback programmable},
author = {Bongers, Bert},
booktitle = {International Computer Music Conference (ICMC)},
file = {::},
keywords = {AHMI,DMI,feedback,force,musical{\_}practice,timbre,vibrotactile},
mendeley-tags = {AHMI,DMI,feedback,force,musical{\_}practice,timbre,vibrotactile},
pages = {171--174},
title = {{The Use of Active Tactile and Force Feedback in Timbre Controlling Electronic Instruments}},
year = {1994}
}
@article{Sinclair2007:DIMPLE,
annote = {SP

TODO},
author = {Sinclair, Stephen and Wanderley, Marcelo M},
file = {::},
keywords = {AHMI,feedback,force,haptic,software,synthesis},
mendeley-tags = {AHMI,feedback,force,haptic,software,synthesis},
pages = {4--7},
title = {{Extending DIMPLE : a rigid body haptic simulator for interactive control of sound .}},
year = {2007}
}
@inproceedings{Merchel2009:vibChair,
author = {Merchel, Sebastian and Altinsoy, M. Ercan},
booktitle = {Haptic and Audio Interaction Design (HAID)},
file = {::},
keywords = {AHMI,audiotactile concert perception,body,complex{\_}signals,multimodal music reproduction,perception,vibration,vibrotactile,whole body vibration},
mendeley-tags = {AHMI,body,complex{\_}signals,perception,vibration,vibrotactile},
pages = {119--127},
title = {{Vibratory and Acoustical Factors in Multimodal Reproduction of Concert DVDs}},
year = {2009}
}
@inproceedings{HSoundplane:NIME2015,
author = {Papetti, Stefano and Schiesser, S{\'{e}}bastien and Fr{\"{o}}hlich, Martin},
booktitle = {New Interfaces for Musical Expression (NIME)},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Papetti, Schiesser, Fr{\"{o}}hlich - 2015 - Multi-point vibrotactile feedback for an expressive musical interface.pdf:pdf},
keywords = {AHMI,DMI,actuated,feedback,multipoint,multitouch,piezo,vibrotactile},
mendeley-tags = {AHMI,DMI,actuated,feedback,multipoint,multitouch,piezo,vibrotactile},
title = {{Multi-point vibrotactile feedback for an expressive musical interface}},
year = {2015}
}
@inproceedings{Young2017,
abstract = {We present the findings of a pilot-study that analysed the role of haptic feedback in a musical context. To closely examine the role of haptics in Digital Musical Instrument (DMI) design an experiment was formulated to measure the users' perception of device usability across four separate feedback stages: fully haptic (force and tactile combined), constant force only, vibrotactile only, and no feedback. The study was piloted over extended periods with the intention of exploring the application and integration of DMIs in real-world musical contexts. Applying a music orientated analysis of this type enabled the investigative process to not only take place over a comprehensive period, but allowed for the exploration of DMI integration in everyday compositional and explorative practices. As with any investigation that involves creativity, it was important that the participants did not feel rushed or restricted. That is, they were given sufficient time to explore and assess the different feedback types without constraint. This provided an accurate and representational set of qualitative data for validating the participants' experience with the different feedback types they were presented with.},
author = {Young, G W and Murphy, D and Weeter, J},
booktitle = {New Interfaces for Musical Expression (NIME)},
file = {::},
keywords = {DMI,evaluation,feedback,force,haptic,performance,quality},
mendeley-tags = {DMI,evaluation,feedback,force,haptic,performance,quality},
pages = {204--209},
title = {{A Qualitative Analysis of Haptic Feedback in Music Focused Exercises}},
url = {http://homes.create.aau.dk/dano/nime17/papers/0038/paper0038.pdf},
year = {2017}
}
@inproceedings{Giordano2015:Metronome,
abstract = {In this paper we present a pilot study evaluating the effec-tiveness of a tactile metronome for music performance and training. Four guitar players were asked to synchronize to a metronome click-track delivered either aurally or via a vibrotactile stimulus. We recorded their performance at different tempi (60 and 120 BPM) and compared the re-sults across modalities. Our results indicate that a tactile metronome can reliably cue participants to follow the tar-get tempo. Such a device could hence be used in musical practice and performances as a reliable alternative to tradi-tional auditory click-tracks, generally considered annoying and distracting by performers.},
author = {Giordano, Marcello and Wanderley, Marcelo M},
booktitle = {Proceedings of the Sound and Music Computing Conference},
file = {::},
isbn = {9780992746629},
keywords = {feedback,metronome,musical{\_}practice,performance,vibrotactile},
mendeley-tags = {feedback,metronome,musical{\_}practice,performance,vibrotactile},
title = {{Follow the Tactile Metronome: Vibrotactile Stimulation for Tempo Synchronization in Music Performance}},
year = {2015}
}
@inproceedings{Pedrosa2011,
author = {Pedrosa, Ricardo and Maclean, Karon E},
booktitle = {IEEE World Haptics Conference},
file = {::},
isbn = {9781457702983},
keywords = {AHMI,auditory,crossmodal,experiment,feedback,haptic,perception,temp{\_}TODO{\_}NIME},
mendeley-tags = {AHMI,auditory,crossmodal,experiment,feedback,haptic,perception,temp{\_}TODO{\_}NIME},
pages = {361--366},
title = {{Perception of Sound Renderings via Vibrotactile Feedback}},
year = {2011}
}
@article{Sinclair2009:DIMPLE,
annote = {SP

TODO},
author = {Sinclair, Stephen and Wanderley, Marcelo M.},
doi = {10.1016/j.intcom.2008.10.012},
file = {::},
issn = {09535438},
journal = {Interacting with Computers},
keywords = {AHMI,feedback,force,haptic,synthesis},
mendeley-tags = {AHMI,feedback,force,haptic,synthesis},
month = {jan},
number = {1-2},
pages = {54--63},
publisher = {Elsevier B.V.},
title = {{A run-time programmable simulator to enable multi-modal interaction with rigid-body systems}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0953543808000714},
volume = {21},
year = {2009}
}
@inproceedings{O'Modhrain2000b,
abstract = {Though musicians rely primarily on their sense of hearing to monitor and adjust the sonnd being produced by their instrument: there exists a second path through which valuable infonnation about the instrument's behavior can be observed - namely the feedback received via the haptic senses, the senses of touch and kinesthesia. The present study tested the hypothesis that leveraging off the musician's unconscious llse of combined auditory and haptic cnes by adding haptic feedback to computer-based musical instruments would improve the "playability" of these instruments. Twenty experienced musicians played a series of short melodies on an unfamiliar computer-based lllusical instrument. The instrument's controller was capable of producing force feedback making it possible to systematically vary the instrument's feel. Results indicate that the presence of haptic feedback improved playing accuracy by approxilllately 23 percent. Moreover haptic feedback which was correlated with changes in the lllusical parameter being controlled produced greater playing accuracy than uncorrelated haptic feedback.},
author = {O'Modhrain, Sile and Chafe, Chris},
booktitle = {ISORA, World Automation Conference (2000)},
keywords = {AHMI,DMI,Theremin,actuated,experiment,feedback,force-feedback,haptic,haptics,music,musical{\_}practice,performance,physical{\_}modeling,pitch,playability,synthesis,temp{\_}TODO{\_}NIME},
mendeley-tags = {AHMI,DMI,actuated,experiment,feedback,haptic,musical{\_}practice,performance,physical{\_}modeling,pitch,playability,temp{\_}TODO{\_}NIME},
title = {{Incorporating Haptic Feedback into Interfaces for Music Applications}},
year = {2000}
}
@article{RocchessoAl:IJHCS:2015,
abstract = {A tool for the multisensory stylus-based exploration of virtual textures was used to investigate how different feedback modalities (static or dynamically deformed images, vibration, sound) affect exploratory gestures. To this end, we ran an experiment where participants had to steer a path with the stylus through a curved corridor on the surface of a graphic tablet/display, and we measured steering time, dispersion of trajectories, and applied force. Despite the variety of subjective impressions elicited by the different feedback conditions, we found that only nonvisual feedback induced significant variations in trajectories and an increase in movement time. In a post-experiment, using a paper-and-wood physical realization of the same texture, we recorded a variety of gestural behaviors markedly different from those found with the virtual texture. With the physical setup, movement time was shorter and texture-dependent lateral accelerations could be observed. This work highlights the limits of multisensory pseudo-haptic techniques in the exploration of surface textures.},
author = {Rocchesso, D. and {Delle Monache}, S. and Papetti, S.},
doi = {10.1016/j.ijhcs.2015.07.005},
issn = {10715819},
journal = {International Journal of Human-Computer Studies},
keywords = {AHMI,Multisensory textures,Pen-based interaction,Pseudo-haptics,Sonic interaction design,audio,feedback,haptic,multisensory,pen,texture,touchscreen,visual},
mendeley-tags = {AHMI,audio,feedback,haptic,multisensory,pen,texture,touchscreen,visual},
month = {aug},
title = {{Multisensory texture exploration at the tip of the pen}},
url = {http://www.sciencedirect.com/science/article/pii/S1071581915001238 http://linkinghub.elsevier.com/retrieve/pii/S1071581915001238},
year = {2015}
}
@inproceedings{GiordanoWanderley:GuitarLearning,
abstract = {This paper presents a full-body vibrotactile display that can be used as a tool to help learning music performance. The system is composed of 10 vibrotactile actuators placed on different positions of the body as well as an extended and modified version of a software tool for generating tactile events, the Fast Afferent/Slow Afferent (FA/SA) application. We carried out initial tests of the system in the context of enhancing the learning process of novice guitar players. In these tests we asked the performers to play the guitar part over a drum and bass-line base track, either heard or felt by the performers through headphones and the tactile display they were wearing. Results show that it is possible to accurately render the representation of the audio track in the tactile channel only, therefore reducing the cognitive load in the auditory channel.},
address = {Padua, Italy},
author = {Giordano, Marcello and Wanderley, Marcelo M},
booktitle = {Sound and Music Computing (SMC)},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Giordano, Wanderley - 2011 - A Learning Interface for Novice Guitar Players using Vibrotactile Stimulation.pdf:pdf},
keywords = {AHMI,feedback,guitar,tuition,vibration},
mendeley-tags = {AHMI,feedback,guitar,tuition,vibration},
title = {{A Learning Interface for Novice Guitar Players using Vibrotactile Stimulation}},
year = {2011}
}
@inproceedings{Frid2014,
abstract = {In this paper we present a study we conducted to assess physical and perceptual properties of a tactile display for a tactile notification system within the CIRMMT Live Elec- tronics Framework (CLEF), a Max-based 1 modular envi- ronment for composition and performance of live electronic music. Our tactile display is composed of two rotating ec- centric mass actuators driven by a PWM signal generated from an Arduino microcontroller. We conducted physical measurements using an accelerometer and two user-based studies in order to evaluate: intensity and spectral peak fre- quency as function of duty cycle, as well as perceptual vi- brotactile absolute and differential threshold. Results, ob- tained through the use of a logit regression model, provide us with precise design guidelines. These guidelines will enable us to ensure robust perceptual discrimination be- tween vibrotactile stimuli at different intensities. Among with other characterizations presented in this study, these guidelines will allow us to better design tactile cues for our notification system for live-electronics performance.},
author = {Frid, Emma and Giordano, Marcello and Schumacher, M Marlon and Wanderley, Marcelo M},
booktitle = {Sound and Music Computing (SMC)},
file = {::},
keywords = {AHMI,evaluation,experiment,feedback,musical{\_}practice,perception,tactile},
mendeley-tags = {AHMI,evaluation,experiment,feedback,musical{\_}practice,perception,tactile},
title = {{Physical and Perceptual Characterization of a Tactile Display for a Live-Electronics Notification System}},
year = {2014}
}
@article{Huang2012,
abstract = {Musicians often say that they not only hear, but also "feel" music. To explore the contribution of tactile information in "feeling" musical rhythm, we investigated the degree that auditory and tactile inputs are integrated in humans performing a musical meter recognition task. Subjects discriminated between two types of sequences, 'duple' (march-like rhythms) and 'triple' (waltz-like rhythms) presented in three conditions: 1) Unimodal inputs (auditory or tactile alone), 2) Various combinations of bimodal inputs, where sequences were distributed between the auditory and tactile channels such that a single channel did not produce coherent meter percepts, and 3) Simultaneously presented bimodal inputs where the two channels contained congruent or incongruent meter cues. We first show that meter is perceived similarly well (70{\%}-85{\%}) when tactile or auditory cues are presented alone. We next show in the bimodal experiments that auditory and tactile cues are integrated to produce coherent meter percepts. Performance is high (70{\%}-90{\%}) when all of the metrically important notes are assigned to one channel and is reduced to 60{\%} when half of these notes are assigned to one channel. When the important notes are presented simultaneously to both channels, congruent cues enhance meter recognition (90{\%}). Performance drops dramatically when subjects were presented with incongruent auditory cues (10{\%}), as opposed to incongruent tactile cues (60{\%}), demonstrating that auditory input dominates meter perception. We believe that these results are the first demonstration of cross-modal sensory grouping between any two senses.},
annote = {SP

TODO},
author = {Huang, Juan and Gamble, Darik and Sarnlertsophon, Kristine and Wang, Xiaoqin and Hsiao, Steven},
doi = {10.1371/journal.pone.0048496},
file = {::},
issn = {1932-6203},
journal = {PloS one},
keywords = {AHMI,auditory,congruence,feedback,haptic,integration,meter,multimodal,music,perception,rhythm,timing},
mendeley-tags = {AHMI,auditory,congruence,feedback,haptic,integration,meter,multimodal,music,perception,rhythm,timing},
month = {jan},
number = {10},
pmid = {23119038},
title = {{Feeling music: integration of auditory and tactile inputs in musical meter perception.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3485368{\&}tool=pmcentrez{\&}rendertype=abstract},
volume = {7},
year = {2012}
}
