Automatically generated by Mendeley Desktop 1.17.9
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@inproceedings{Palacio2015,
address = {Madrid},
author = {Palacio, Pablo and Bisig, Daniel},
booktitle = {Proceedings of the Congreso Internacional Espacios Sonoros y Audiovisuales},
title = {{Neural Narratives 1: Phantom Limb. Connecting Cognitive Neurosciences, Sound Synthesis, Generative Video and Dance}},
year = {2015}
}
@book{Miranda2006,
author = {Miranda, Eduardo and Wanderley, Marcelo M.},
edition = {AR Edition},
title = {{New Digital Musical Instruments: Control and Interaction Beyond the Keyboard}},
year = {2006}
}
@article{Camurri2016,
author = {Camurri, Antonio and Volpe, Gualtiero and Piana, Stefano and Mancini, Maurizio and Niewiadomski, Radoslaw and Ferrari, Nicola and Canepa, Corrado},
doi = {10.1145/2948910.2948927},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Camurri et al. - 2016 - The Dancer in the Eye Towards a Multi-Layered Computational Framework of Qualities in Movement.pdf:pdf},
isbn = {9781450343077},
journal = {Proceedings of the 3rd International Symposium on Movement and Computing},
pages = {6:1--6:7},
title = {{The Dancer in the Eye: Towards a Multi-Layered Computational Framework of Qualities in Movement}},
year = {2016}
}
@book{Bohnsack2008,
address = {Opladen},
author = {Bohnsack, Ralf},
title = {{Rekonstruktive Sozialforschung – Einf{\"{u}}hrung in qualitative Methoden}},
year = {2008}
}
@article{Weinberg2005,
abstract = {This article attempts to define and classify the aesthetic and technical principles of interconnected musical networks. It presents an historical overview of technological innovations that were instrumental for the development of the field and discusses a number of paradigmatic musical networks that are based on these technologies. A classification of online and local-area musical networks then leads to an attempt to define a taxonomical and theoretical framework for musical interconnectivity, addressing goals and motivations, social organizations and perspectives, network architectures and topologies, and musical content and control. The article concludes with a number of design suggestions for the development of effective interconnected musical networks.},
author = {Weinberg, Gil},
doi = {10.1162/0148926054094350},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Weinberg - 2005 - Interconnected musical networks Toward a theoretical framework.pdf:pdf},
isbn = {0148926054094},
issn = {0148-9267},
journal = {Computer Music Journal},
number = {2},
pages = {23--39},
title = {{Interconnected musical networks: Toward a theoretical framework}},
url = {http://opera.media.mit.edu/publications/weinberg{\_}cmj2005{\_}interconnected{\_}musical{\_}networks.pdf},
volume = {29},
year = {2005}
}
@article{Gonzalez2012,
abstract = {The design of interactive dance is a challenging endeavor because both dance and computing are in themselves full of complexity, thus to create a cohesive union of the two involves much trial and error and a mutual disciplinary understanding. Since interactive dance is a performing art, technologists working as designers must consider how all of the parts -- choreography, media, interactivity -- are integrated to inform the overall gestalt and intent of the piece. To this end, we offer five design principles for making interactive dance: Connected Kinetics, Augmented Expression, Aesthetic Harmony, Interactive Build, and Integrated Process. These design principles have emerged from our practice-based research in collaboratively producing six different interactive dance pieces over the past four years.},
author = {Gonzalez, Berto and Carroll, Erin and Latulipe, Celine},
doi = {10.1145/2399016.2399078},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Gonzalez, Carroll, Latulipe - 2012 - Dance-inspired technology, technology-inspired dance.pdf:pdf},
isbn = {9781450314824},
journal = {Proceedings of the 7th Nordic Conference on Human-Computer Interaction Making Sense Through Design - NordiCHI '12},
pages = {398},
title = {{Dance-inspired technology, technology-inspired dance}},
url = {http://dl.acm.org/citation.cfm?doid=2399016.2399078},
year = {2012}
}
@inproceedings{Lambert2016,
abstract = {The HTML5 standard is wide-spread on mobile devices. In combination with the Web Audio API, it allows for massively distributed real-time audio rendering. But timing issues exist, mainly because of the lack of standard inter-device synchronisation. This paper proposes a synchronisation solution based on HTML5. Using a shared reference time, we achieved the distributed rendering of audio events with an individual accuracy of 1 to 10 ms, 5 ms in standard deviation, which is more accurate than the audio block duration, for any device that we measured.},
address = {Atlanta},
author = {Lambert, Jean-Philippe and Robaszkiewicz, S{\'{e}}bastien and Schnell, Norbert},
booktitle = {Proceedings of the 2nd Web Audio Conference (WAC-2016)},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Lambert, Robaszkiewicz, Schnell - 2016 - Synchronisation for Distributed Audio Rendering over Heterogeneous Devices, in HTML5.pdf:pdf},
keywords = {Real-time systems,Synchronisation,Web Audio API},
title = {{Synchronisation for Distributed Audio Rendering over Heterogeneous Devices, in HTML5}},
year = {2016}
}
@inproceedings{Knotts2014,
abstract = {This paper reports the results of an online survey of 160 laptop ensembles and the relative democracy of their organisational and social structures. For the purposes of this research a laptop ensemble is defined as a performing group of three or more musicians for whom the laptop is the main sound generating source and who typically perform together in the same room. The concept of democracy (i.e. governance by members of the group) has been used as a starting point to assess firstly what types of organisational structures are currently used in laptop ensembles and secondarily to what extent laptop ensembles consider the implications of organisational and social structure on their musical output. To assess this I recorded a number of data points including ensemble size, whether the group has a director or conductor, use of homogenous vs. heterogenous hardware and software, whether they perform composed pieces or mainly improvise, the level of network interaction and whether or not the ensemble has an academic affiliation. The survey allowed me to define a scale of democracy in laptop ensembles and typical features of the most and least democratic groups. Some examples are given of democratic and autocratic activity in existing laptop ensembles. This work is part of a larger scale project investigating the effect of social structures on the musical output of laptop ensembles.},
address = {London, United Kingdom},
author = {Knotts, Shelly and Collins, Nick},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
editor = {Caramiaux, Baptiste and Tahiroglu, Koray and Fiebrink, Rebecca and Tanaka, Atau},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Knotts, Collins - 2014 - The Politics of Laptop Ensembles A Survey of 160 Laptop Ensembles and their Organisational Structures.pdf:pdf},
pages = {191--194},
publisher = {Goldsmiths, University of London},
title = {{The Politics of Laptop Ensembles: A Survey of 160 Laptop Ensembles and their Organisational Structures}},
url = {http://www.nime.org/proceedings/2014/nime2014{\_}521.pdf},
year = {2014}
}
@article{Hunt2003,
abstract = {This paper presents a review of a series of experiments which have contributed towards the understanding of the mapping layer in electronic instruments. It challenges the assumption that an electronic instrument consists solely of an interface and a sound generator. It emphasises the importance of the mapping between input parameters and sound parameters, and suggests that this can define the very essence of an instrument. The terms involved with mapping are defined, and existing literature reviewed and summarised. A model for understanding the design of such mapping strategies for electronic instruments is put forward, along with a roadmap of ongoing research focussing on the testing and evaluation of such mapping strategies.},
author = {Hunt, Andy and Wanderley, Marcelo M. and Paradis, Matthew},
doi = {10.1076/jnmr.32.4.429.18853},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Hunt, Wanderley, Paradis - 2003 - The Importance of Parameter Mapping in Electronic Instrument Design.pdf:pdf},
isbn = {1-87465365-8},
issn = {0929-8215},
journal = {Journal of New Music Research},
keywords = {electronic musical instruments,human-computer interaction,mapping strategies},
number = {4},
pages = {429--440},
title = {{The Importance of Parameter Mapping in Electronic Instrument Design}},
url = {http://portal.acm.org/citation.cfm?id=1085207{\%}5Cnhttp://www.nime.org/2004/NIME02/hunt.pdf},
volume = {32},
year = {2003}
}
@article{Oh2010,
abstract = {In this paper, we describe the development of the Stanford Mobile Phone Orchestra (MoPhO) since its inceptionin 2007. As a newly structured ensemble of musicians withiPhones and wearable speakers, MoPhO takes advantageof the ubiquity and mobility of smartphones as well asthe unique interaction techniques offered by such devices.MoPhO offers a new platform for research, instrument design, composition, and performance that can be juxtaposedto that of a laptop orchestra. We trace the origins of MoPhO,describe the motivations behind the current hardware andsoftware design in relation to the backdrop of current trendsin mobile music making, detail key interaction conceptsaround new repertoire, and conclude with an analysis onthe development of MoPhO thus far.},
author = {Oh, Jieun and Herrera, Jorge and Bryan, Nicholas J and Dahl, Luke and Wang, Ge},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Oh et al. - 2010 - Evolving The Mobile Phone Orchestra.pdf:pdf},
journal = {Proceedings of the 2010 Conference on New Interfaces for Musical Expression (NIME-10)},
keywords = {iPhone,live performance,mobile music,mobile phone orchestra},
pages = {82--87},
title = {{Evolving The Mobile Phone Orchestra}},
url = {http://www.nime.org/proceedings/2010/nime2010{\_}082.pdf},
year = {2010}
}
@inproceedings{Machover1989,
author = {Machover, Tod and Chung, Joe},
booktitle = {Proceedings of the International Computer Music Conference},
title = {{Hyperinstruments: Musically Intelligent and Interactive Performance and Creativity Systems}},
year = {1989}
}
@inproceedings{Schacher2013,
abstract = {This article documents a class that teaches gestural interaction and juxtaposestraditional instrumental skills with digital musical instrument concepts. Inorder to show the principles and reflections that informed the choices made indeveloping this syllabus, fundamental elements of an instrument-bodyrelationship and the perceptual import of sensori-motor integration areinvestigated. The methods used to let participants learn in practicalexperimental settings are discussed, showing a way to conceptualise andexperience the entire workflow from instrumental sound to electronictransformations by blending gestural interaction with digital musicalinstrument techniques and traditional instrumental playing skills. Thetechnical interfaces and software that were deployed are explained, focussingof the interactive potential offered by each solution. In an attempt tosummarise and evaluate the impact of this course, a number of insights relatingto this specific pedagogical situation are put forward. Finally, concreteexamples of interactive situations that were developed by the participants areshown in order to demonstrate the validity of this approach.},
address = {Daejeon, Republic of Korea},
author = {Schacher, Jan C},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
editor = {Yeo, W and Lee, K and Sigman, A and H., Ji and Wakefield, G},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Schacher - 2013 - Hybrid Musicianship - Teaching Gestural Interaction with Traditional and Digital Instruments.pdf:pdf},
keywords = {digital musical instruments,enactive approach,gestural interaction,mapping,pedagogy},
pages = {55--60},
publisher = {Graduate School of Culture Technology, KAIST},
title = {{Hybrid Musicianship - Teaching Gestural Interaction with Traditional and Digital Instruments}},
url = {http://nime2013.kaist.ac.kr/},
year = {2013}
}
@inproceedings{Marshall2011,
abstract = {This paper deals with the effects of integrated vibrotactile feedback on the "feel" of a digital musical instrument(DMI). Building on previous work developing a DMI withintegrated vibrotactile feedback actuators, we discuss howto produce instrument-like vibrations, compare these simulated vibrations with those produced by an acoustic instrument and examine how the integration of this feedbackeffects performer ratings of the instrument. We found thatintegrated vibrotactile feedback resulted in an increase inperformer engagement with the instrument, but resulted ina reduction in the perceived control of the instrument. Wediscuss these results and their implications for the design ofnew digital musical instruments.},
address = {Oslo, Norway},
author = {Marshall, Mark T. and Wanderley, Marcelo M.},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
editor = {Jensenius, Alexander R and Tveit, Anders and Godoy, Rolf I and Overholt, Dan},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Marshall, Wanderley - 2011 - Examining the Effects of Embedded Vibrotactile Feedback on the Feel of a Digital Musical Instrument.pdf:pdf},
keywords = {Digital Musical Instruments,Feel,Loudspeakers,Vibrotactile Feedback},
pages = {399--404},
title = {{Examining the Effects of Embedded Vibrotactile Feedback on the Feel of a Digital Musical Instrument}},
url = {http://www.nime.org/proceedings/2011/nime2011{\_}399.pdf},
year = {2011}
}
@article{Murray-browne2012,
abstract = {criticisms in DMIs: Expressive capabilities, Usability, Virtuosity, Visual aspects (gestures that arise when performing them lacking expression), Transparency * causality (to understand the relationship between action-sound (Section 2.2.10 + 3.3.5 -- but it shifts audience focus from music to the understanding the working of instrument).},
author = {Murray-browne, Tim},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Murray-browne - 2012 - Interactive music Balancing creative freedom with musical development.pdf:pdf},
journal = {Thesis},
number = {October},
title = {{Interactive music : Balancing creative freedom with musical development}},
year = {2012}
}
@inproceedings{Bisig2014,
address = {Rome},
author = {Bisig, Daniel and Palacio, Pablo},
booktitle = {Proceedings of the Generative Art Conference},
pages = {92--107},
title = {{Phantom Limb -- Hybrid Embodiments for Dance}},
year = {2014}
}
@article{Manning2006,
abstract = {Erin Manning's understanding of the body as 'technogenetic' (Manning) is significant within this vocabulary.},
author = {Manning, Erin},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Manning - 2006 - Prosthetics Making Sense Dancing the Technogenetic Body.pdf:pdf},
journal = {Fibreculture},
number = {9},
pages = {1--7},
title = {{Prosthetics Making Sense: Dancing the Technogenetic Body}},
volume = {9},
year = {2006}
}
@article{Gimenes2016,
abstract = {This paper introduces Performance Without Borders and Embodied iSound, two sound installations performed at the 2016 Peninsula Arts Contemporary Music Festival at Plymouth University. Sharing in common the use of smartphones to afford real-time audience participation, two bespoke distributed computer systems (Sherwell and Levinsky Music, respectively). Whilst the first one implements a cloud-based voting system, the second implements movement tracking and iBeacon-based indoor-positioning to control the choice of soundtracks, audio synthesis, and surround sound positioning, among other parameters. The general concepts of the installations, in particular design and interactive possibilities afforded by the computer systems are presented.},
author = {Gimenes, Marcelo and Largeron, Pierre-Emmanuel and Miranda, Eduardo R},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Gimenes, Largeron, Miranda - 2016 - Frontiers Expanding Musical Imagination With Audience Participation.pdf:pdf},
isbn = {978-1-925455-13-7},
journal = {Proceedings of the International Conference on New Interfaces for Musical Expression},
keywords = {Sound installation,audience participation: smartphone},
pages = {350--354},
title = {{Frontiers : Expanding Musical Imagination With Audience Participation}},
url = {http://www.nime.org/proceedings/2016/nime2016{\_}paper0068.pdf},
volume = {16},
year = {2016}
}
@article{Hindle2015,
author = {Hindle, Abram},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Hindle - 2015 - Orchestrating Your Cloud-orchestra.pdf:pdf},
journal = {Proceedings of the International Conference on New Interfaces for Musical Expression},
pages = {121--125},
title = {{Orchestrating Your Cloud-orchestra}},
year = {2015}
}
@inproceedings{Schacher2015,
address = {Baton Rouge},
author = {Schacher, Jan and Miyama, Chikashi and Bisig, Daniel},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
pages = {347--350},
title = {{Gestural Electronic Music Using Machine Learning as Generative Device}},
year = {2015}
}
@inproceedings{Fober2012,
abstract = {INScore is an open source framework for the design of interactive, augmented, live music scores. Augmented music scores are graphic spaces providing representation, composition and manipulation of heterogeneous and arbitrary music objects (music scores but also images, text, signals...), both in the graphic and time domains. INScore includes also a dynamic system for the representation of the music performance, considered as a specific sound or gesture instance of the score, and viewed as signals. It integrates an event based interaction mechanism that opens the door to original uses and designs, transforming a score as a user interface or allowing a score self-modification based on temporal events. This paper presents the system features, the underlying formalisms, and introduces the OSC based scripting language.},
address = {Stanford},
author = {Fober, Dominique and Orlarey, Yann and Letz, St{\'{e}}phane},
booktitle = {Proceedings of the Linux Audio Conference},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Fober, Orlarey, Letz - 2012 - INScore An Environment for the Design of Live Music Scores.pdf:pdf},
keywords = {Augmented Score,Mobile Score,interaction,score,signal,synchronization},
mendeley-tags = {Augmented Score,Mobile Score},
pages = {47--54},
title = {{INScore An Environment for the Design of Live Music Scores}},
year = {2012}
}
@inproceedings{Park2013,
abstract = {SSN (Sound Surfing Network) is a performance system that provides a new musicalexperience by incorporating mobile phone-based spatial sound control tocollaborative music performance. SSN enables both the performer and theaudience to manipulate the spatial distribution of sound using the smartphonesof the audience as distributed speaker system. Proposing a new perspective tothe social aspect music appreciation, SSN will provide a new possibility tomobile music performances in the context of interactive audience collaborationas well as sound spatialization.},
address = {Daejeon, Republic of Korea},
author = {Park, Saebyul and Ban, Seonghoon and Hong, Dae Ryong and Yeo, Woon Seung},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Park et al. - 2013 - Sound Surfing Network (SSN) Mobile Phone-based Sound Spatialization with Audience Collaboration.pdf:pdf},
keywords = {Mobile music,audience participation,digital performance,smartphone,spatial sound control},
pages = {111--114},
publisher = {Graduate School of Culture Technology, KAIST},
title = {{Sound Surfing Network (SSN): Mobile Phone-based Sound Spatialization with Audience Collaboration}},
url = {http://nime.org/proceedings/2013/nime2013{\_}305.pdf},
year = {2013}
}
@article{Latulipe2011,
author = {Latulipe, Celine and Wilson, David and Huskey, Sybil and Gonzalez, Berto and Word, Melissa},
doi = {10.1145/2069618.2069639},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Latulipe et al. - 2011 - Temporal integration of interactive technology in dance.pdf:pdf},
isbn = {9781450308205},
journal = {Proceedings of the 8th ACM conference on Creativity and cognition - C{\&}C '11},
keywords = {arts,creativity,dance,interdisciplinary integration,temporal effects},
pages = {107},
title = {{Temporal integration of interactive technology in dance}},
url = {http://dl.acm.org/citation.cfm?id=2069618.2069639},
year = {2011}
}
@article{Overholt2011,
abstract = {This article presents recent developments in actuated musical instruments created by the authors, who also describe an ecosystemic model of actuated performance activities that blur traditional boundaries between the physical and virtual elements of musical interfaces. Actuated musical instruments are physical instruments that have been endowed with virtual qualities controlled by a computer in real-time but which are nevertheless tangible. These instruments provide intuitive and engaging new forms of interaction. They are different from traditional (acoustic) and fully automated (robotic) instruments in that they produce sound via vibrating element(s) that are co-manipulated by humans and electromechanical systems. We examine the possibilities that arise when such instruments are played in different performative environments and music-making scenarios, and we postulate that such designs may give rise to new methods of musical performance. The Haptic Drum, the Feedback Resonance Guitar, the Electromagnetically Prepared Piano, the Overtone Fiddle and Teleoperation with Robothands are described, along with musical examples and reflections on the emergent properties of the performance ecologies that these instruments enable. We look at some of the conceptual and perceptual issues introduced by actuated musical instruments, and finally we propose some directions in which such research may be headed in the future},
author = {Overholt, Dan and Berdahl, Edgar and Hamilton, Robert},
doi = {10.1017/S1355771811000100},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Overholt, Berdahl, Hamilton - 2011 - Advancements in Actuated Musical Instruments(4).pdf:pdf},
isbn = {1355771811},
issn = {1355-7718},
journal = {Organised Sound},
number = {02},
pages = {154--165},
title = {{Advancements in Actuated Musical Instruments}},
url = {http://www.journals.cambridge.org/abstract{\_}S1355771811000100},
volume = {16},
year = {2011}
}
@article{Dannenberg2016,
abstract = {O2 is a new communication protocol and implementation for music systems that aims to replace Open Sound Control (OSC). Many computer musicians routinely deal with problems of interconnection in local area networks, unre- liable message delivery, and clock synchronization. O2 solves these problems, offering named services, automat- ic network address discovery, clock synchronization, and a reliable message delivery option, as well as interoperability with existing OSC libraries and applications. Aside from these new features, O2 owes much of its design to OSC and is mostly compatible with and similar to OSC. O2 addresses the problems of inter-process communication with a minimum of complexity.},
author = {Dannenberg, Roger B},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Dannenberg - 2016 - O2 Rethinking Open Sound Control.pdf:pdf},
journal = {Proceedings of the International Computer Music Conference},
keywords = {Network Time Synchronisation,rethinking open sound control},
mendeley-tags = {Network Time Synchronisation},
pages = {493--496},
title = {{O2 : Rethinking Open Sound Control}},
year = {2016}
}
@article{Gresham-Lancaster1998,
author = {Gresham-Lancaster, Scot},
doi = {10.2307/1513398},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Gresham-Lancaster - 1998 - The Aesthetics and History of the Hub The Effects of Changing Technology on Network Computer Music.pdf:pdf},
isbn = {0961-1215},
issn = {09611215},
journal = {Leonardo Music Journal},
keywords = {electronic music,internet,music {\&} technology},
number = {1},
pages = {39--44},
title = {{The Aesthetics and History of the Hub: The Effects of Changing Technology on Network Computer Music}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=aph{\&}AN=9152101{\&}site=ehost-live},
volume = {8},
year = {1998}
}
@incollection{ToroPerez2015,
author = {{Toro P{\'{e}}rez}, Germ{\'{a}}n},
booktitle = {Disembodied Voice},
editor = {Rey, Anton and {Toro P{\'{e}}rez}, Germ{\'{a}}n},
isbn = {978 3 89581 349 8},
pages = {27--32},
publisher = {Alexander Verlag},
title = {{Nicht Effekte. Ph{\"{a}}nomene! Elektroakustische Technik und Stimme im Kontext k{\"{u}}nstlerischer Forschung.}},
year = {2015}
}
@techreport{Levin2001,
abstract = {Dialtones is a large-scale concert performance whose sounds are wholly produced through the carefully choreographed dialing and ringing of the audience's own mobile phones. Because the exact location and tone of each participant's mobile phone can be known in advance, Dialtones affords a diverse range of unprecedented sonic phenomena and musically interesting structures. Moreover, by directing our attention to the unexplored musical potential of a ubiquitous modern appliance, Dialtones inverts our understandings of private sound, public space, electromagnetic etiquette, and the fabric of the communications network which connects us. Dialtones premiered in two consecutive concerts in September, 2001, as a co-production of Golan Levin and TAKEOVER: The 2001 Ars Electronica Festival. It was subsequently presented in seventeen performances in May/June 2002 at the Swiss National Exposition. Dialtones begins with a brief preparation phase prior to its performance, during which the members of the audience register their wireless telephone numbers at a cluster of secure Web kiosks. In exchange for this information, the participants receive seating assignment tickets for the concert venue, and new “ringtones” are then automatically downloaded to their handsets. During the concert itself, the audience's mobile phones are brought to life by a small group of musicians, who perform the phones en masse by dialing them up with a specially designed, visual-musical software instrument. Because the audience's positions and sounds are known to the Dialtones computer system, the performers can create spatially-distributed melodies and chords, as well as novel textural phenomena like waves of polyphony which cascade across the crowd; these musical structures, moreover, are visualized by a large projection system connected to the performers' interfaces. Towards the end of its half-hour composition, Dialtones builds to a remarkable crescendo in which nearly two hundred mobile phones peal simultaneously. It is hoped that the experience of Dialtones can permanently alter the way in which its participants think about the cellular space we inhabit.},
author = {Levin, Golan and Gibbons, Scott and Shakar, Gregory and Sohrawardy, Yasmin and Gruber, Joris and Lehner, Jörg and Schmidl, Gunther and Semlak, Erich},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Levin et al. - 2001 - Dialtones (A Telesymphony).pdf:pdf},
title = {{Dialtones (A Telesymphony)}},
year = {2001}
}
@book{Ferscha2017,
abstract = {Research Challenges in Human Computer Confluence},
annote = {NULL},
author = {Ferscha, Alois},
booktitle = {Agenda},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Ferscha - 2017 - Human Computer Confluence.pdf:pdf},
isbn = {9783200033443},
title = {{Human Computer Confluence}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.399.6943{\&}rep=rep1{\&}type=pdf},
year = {2017}
}
@phdthesis{Udell2012,
abstract = {This dissertation is dedicated to combining some of the latest ultra-low power microprocessor and radio frequency (RF) wireless technology to build a new wireless sensor network (WSN) for musical instruments called eMotion. The hardware is designed to address three current issues in the field of augmented musical instruments: single-serving innovation, accessibility, and transparency. This interface implements a unique design approach when compared to other similar music interfaces currently available. To this end, the eMotion hardware will be modular, reversible, non-invasive, and reconfigurable – permitting a musician to interact with computers in live performance using the physical gestures of their instrument. Beginning with a general account of historic developments and technological precedents – the aesthetics of augmented instrument design will be discussed in relief to other design approaches. In response to the issues facing augmented instrument development in the literature, a conceptual framework for the design of the eMotion system will be constructed based on the notions of musical gesture. The second half of the dissertation consists of technical documentation, construction, limitations, and potential applications of this unique system. An account implementing this new wireless gestural interface on the bass trombone will also be discussed. Also included is a piece composed by the author for Flute, Berimbau, and Live Electronics. The original version is a piece for live performers and electroacoustic sound for four channels. It is presented here as a stereo reduction along with the MaxMSP software performance program on a data CD.},
author = {Udell, Chester James},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Udell - 2012 - Toward intelligent musial instruments new wireless modular gestural control interfaces.pdf:pdf},
pages = {1--113},
title = {{Toward intelligent musial instruments: new wireless modular gestural control interfaces}},
year = {2012}
}
@article{Vickery2016,
abstract = {The rhizome concept explored by Deleuze and Guatarri has had an important influence on formal thinking in music and new media. This paper explores the development of rhizomatic musical scores that are arranged cartographically with nodal points allowing for alternate pathways to be traversed. The challenges of pre-digital exemplars of rhizomatic structure are discussed. It follows the development of concepts and technology used in the creation of five works by the author Ubahn c. 1985: the Rosenberg Variations [2012], The Last Years [2012], Sacrificial Zones [2014], detritus [2015] and trash vortex [2015]. The paper discusses the potential for the evolution of novel formal structures using rhizomatic structures.},
author = {Vickery, Lindsay},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Vickery - 2016 - Rhizomatic approaches to screen-based music notation.pdf:pdf},
isbn = {978-1-925455-13-7},
journal = {Proceedings of the International Conference on New Interfaces for Musical Expression},
keywords = {Animated Notation,Mobile Score,Networking,Open Form,Rhizome.},
mendeley-tags = {Mobile Score,Open Form},
pages = {394--400},
title = {{Rhizomatic approaches to screen-based music notation}},
url = {http://www.nime.org/proceedings/2016/nime2016{\_}paper0078.pdf},
volume = {16},
year = {2016}
}
@article{Hsu2015,
author = {Hsu, Aurie and Kemper, Steven},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Hsu, Kemper - 2015 - Kinesonic Composition as Choreographed Sound Composing Gesture in Sensor-Based Music.pdf.pdf:pdf},
isbn = {0984527443},
pages = {412--415},
title = {{Kinesonic Composition as Choreographed Sound: Composing Gesture in Sensor-Based Music.pdf}},
year = {2015}
}
@article{Ostersjo2016,
abstract = {This paper discusses musical gesture from an understanding of musical perception as embodied and enactive, also drawing specifically on Denis Smalley's [(2007). Space- form and the acousmatic image. Organised Sound, 12(1), 35–58] analysis of performed space. I will provide examples of how choreographies (performed by musicians, with and without their instruments), new music (for Vietnamese and Western instruments), installations, and video art have all been drawn from analysis of gesture in {\"{O}}stersj{\"{o}}'s performance of the guitar composition Toccata Orpheus by Rolf Riehm [1990. Toccata Orpheus. Munich: Ricordi]. In Riehm's piece, the bodily action of the performer is treated as an intentional compositional parameter and the notated structure thus generates a specific choreography in performance. In Go To Hell, this approach is taken further towards the development of a gesture-based compositional practice, where composition is understood, not as the organisation of sound objects, but as the structuring of gestural-sonic objects.},
author = {{\"{O}}stersj{\"{o}}, Stefan},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/{\"{O}}stersj{\"{o}} - 2016 - Go To Hell Towards a Gesture-Based Compositional Practice.pdf:pdf},
journal = {Contemporary Music Review},
keywords = {embodied cognition,musical gesture,performer,s analysis,transcription},
number = {4-5},
pages = {4},
title = {{Go To Hell : Towards a Gesture-Based Compositional Practice}},
volume = {35},
year = {2016}
}
@inproceedings{Manousakis2012,
abstract = {This paper presents the system and technology developed for the distributed, micro-telematic, interactive sound art installation, The Network Is A Blind Space. The piece uses sound to explore the physical yet invisible electromagnetic spaces created by Wireless Local Area Networks (WLANs). To this end, the author created a framework for indoor WiFi localization, providing a variety of control data for various types of `musical echolocation'. This data, generated mostly by visitors exploring the installation while holding WiFi-enabled devices, is used to convey the hidden properties of wireless networks as dynamic spaces through an artistic experience.},
address = {Ann Arbor, Michigan},
author = {Manousakis, Stelios},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Manousakis - 2012 - Network spaces as collaborative instruments WLAN trilateration for musical echolocation in sound art.pdf:pdf},
keywords = {Network music,Pure Data,RjDj,SuperCollider,WiFi,collaborative instrument,distributed music,echolocation,electromagnetic signals,interactivity,mapping,mobile music,site-specific,sound art installation,traceroute,trilateration},
publisher = {University of Michigan},
title = {{Network spaces as collaborative instruments: {\{}WLAN{\}} trilateration for musical echolocation in sound art}},
url = {http://www.nime.org/proceedings/2012/nime2012{\_}142.pdf},
year = {2012}
}
@incollection{Swift2013,
abstract = {Improvisational group music-making, informally known as ‘jamming', has its own cultures and conventions of musical interaction. One characteristic of this interaction is the primacy of the experience over the musical artefact—in some sense the sound created is not as important as the feeling of being ‘in the groove'. As computing devices infiltrate creative, open-ended task domains, what can HumanComputer Interaction (HCI) learn from jamming? How do we design systems where the goal is not an artefact but a felt experience? This chapter examines these issues in light of an experiment involving ‘Viscotheque', a novel group music-making environment based on the iPhone.},
author = {Swift, Ben},
booktitle = {Music and Human-Computer Interaction},
doi = {10.1007/978-1-4471-2990-5},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Swift - 2013 - Chasing a Feeling Experience in Computer Supported Jamming.pdf:pdf},
isbn = {978-1-4471-2989-9},
pages = {85--99},
title = {{Chasing a Feeling: Experience in Computer Supported Jamming}},
url = {http://link.springer.com/10.1007/978-1-4471-2990-5},
year = {2013}
}
@article{Smalley2007a,
abstract = {The analytical discussion of acousmatic music can benefit from being based on spatial concepts, and this article aims to provide a framework for investigation. A personal experience of soundscape listening is the starting point, and uncovers basic ideas relating to the disposition and behaviour of sounding content, and listening strategy. This enables the opening out of the discussion to include source-bonded sounds in general, giving particular consideration to how experience of sense modes other than the aural are implicated in our understanding of space, and in acousmatic listening. Attention then shifts to a source-bonded spatial model based on the production of space by the gestural activity of music performance, prior to focusing in more detail on acousmatic music, initially by delving into spectral space, where ideas about gravitation and diagonal forces are germane. This leads to concepts central to the structuring of perspectival space in relation to the vantage point of the listener. The final section considers a methodology for space-form investigation. 1. INTRODUCTION Acousmatic music is the only sonic medium},
author = {Smalley, Denis},
doi = {10.1017/S1355771807001665},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Smalley - 2007 - Space-form and the acousmatic image.pdf:pdf},
isbn = {1355-7718},
issn = {1355-7718},
journal = {Organised Sound},
number = {1},
pages = {35--58},
title = {{Space-form and the acousmatic image}},
volume = {12},
year = {2007}
}
@article{Shaer2010,
abstract = {In the last two decades, Tangible User Interfaces (TUIs) have emerged as a new interface type that interlinks the digital and physical worlds. Drawing upon users' knowledge and skills of interaction with the real non-digital world, TUIs show a potential to enhance the way in which people interact with and leverage digital information. However, TUI research is still in its infancy and extensive research is required in order to fully understand the implications of tangible user interfaces, to develop technologies that further bridge the digital and the physical, and to guide TUI design with empirical knowledge. This monograph examines the existing body of work on Tangible User Interfaces. We start by sketching the history of tangible user interfaces, examining the intellectual origins of this field. We then present TUIs in a broader context, survey application domains, and review frameworks and taxonomies. We also discuss conceptual foundations of TUIs including perspectives from cognitive sciences, psychology, and philosophy. Methods and technologies for designing, building, and evaluating TUIs are also addressed. Finally, we discuss the strengths and limitations of TUIs and chart directions for future research.},
annote = {NULL},
author = {Shaer, Orit and Hornecker, Eva},
doi = {http://dx.doi.org/10.1561/1100000026},
journal = {Foundations and Trends in Human–Computer Interaction},
number = {1-2},
pages = {1--137},
publisher = {now Publishers Inc.},
title = {{Tangible User Interfaces: Past, Present, and Future Directions}},
volume = {3},
year = {2010}
}
@inproceedings{Murray-Browne2010,
author = {Murray-Browne, Tim and Mainstone, Di and Bryan-Kinns, Nick and Plumbley, Mark D},
booktitle = {Audio Engineering Society Convention 128},
title = {{The Serendiptichord: A Wearable Instrument for Contemporary Dance Performance}},
url = {http://www.aes.org/e-lib/browse.cfm?elib=15435},
year = {2010}
}
@book{Hall1966,
address = {New York},
author = {Hall, Edward T.},
isbn = {0-385-08476-5},
publisher = {Anchor Books},
title = {{The Hidden Dimension}},
year = {1966}
}
@article{Tilbian2016,
abstract = {Stride is a declarative and reactive domain specific pro- gramming language for real-time sound synthesis, process- ing, and interaction design. Through hardware resource abstraction and separation of semantics from implemen- tation, a wide range of computation devices can be tar- geted such as microcontrollers, system-on-chips, general purpose computers, and heterogeneous systems. With a novel and unique approach at handling sampling rates as well as clocking and computation domains, Stride prompts the generation of highly optimized target code. The design of the language facilitates incremental learning of its fea- tures and is characterized by intuitiveness, usability, and self-documentation. Users of Stride can write code once and deploy on any supported hardware. 1.},
author = {Tilbian, Joseph},
journal = {Proceedings of the International Computer Music Conference},
pages = {472--478},
title = {{Stride : A Declarative and Reactive Language for Sound Synthesis and Beyond}},
year = {2016}
}
@article{Vickery2012,
abstract = {This article examines the evolution of music notational practices from avant-garde-era experiments in 'mobility' to the advent of the digital 'screen score'. It considers the varied goals of the composers who initiated these developments and the dissonance between these goals and the practical possibilities actually afforded by the paper score. The advent of graphical computing is charted along with the consequent expansion of possibilities afforded by screening the score from a platform that also provides the potential for performer coordination, sound synthesis and transformation. The performative, interactive and formal implications of these possibilities are considered.},
author = {Vickery, Lindsay},
doi = {10.1017/S1355771812000052},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Vickery - 2012 - The Evolution of Notational Innovations from the Mobile Score to the Screen Score.pdf:pdf},
isbn = {1355771812000},
issn = {1355-7718},
journal = {Organised Sound},
keywords = {Mobile Score,evolution of notational innovations,from the mobile score,to the screen score},
mendeley-tags = {Mobile Score},
number = {02},
pages = {128--136},
pmid = {1026946858},
title = {{The Evolution of Notational Innovations from the Mobile Score to the Screen Score}},
url = {http://www.journals.cambridge.org/abstract{\_}S1355771812000052},
volume = {17},
year = {2012}
}
@article{Perrotta2014,
author = {Perrotta, Andre V and Menezes, Flo and Martins, Luis Gustavo},
journal = {Proc. Joint Conference ICMC - SMC 2014},
title = {{Modelling the live-electronics in electroacoustic music using particle systems}},
year = {2014}
}
@article{Fehr,
author = {Fehr, Jonas},
isbn = {9781450334570},
pages = {160--163},
title = {{P160-Fehr}}
}
@article{Kaltenbrunner2006,
abstract = {The reacTable* is a novel multi-user electro-acoustic musical instrument with a tabletop tangible user interface. In this paper we focus on the various collaborative aspects of this new instrument as well as on some of the related technical details such as the networking infrastructure. The instrument can be played both in local and remote collaborative scenarios and was designed from the very beginning to serve as a musical instrument for several simultaneous players},
author = {Kaltenbrunner, Martin and Jord{\`{a}}, Sergi and Geiger, G{\"{u}}nter and Alonso, Marcos},
doi = {10.1109/WETICE.2006.68},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Kaltenbrunner et al. - 2006 - The reacTable A collaborative musical instrument.pdf:pdf},
isbn = {0769526233},
issn = {15244547},
journal = {Proceedings of the Workshop on Enabling Technologies: Infrastructure for Collaborative Enterprises, WETICE},
pages = {406--411},
title = {{The reacTable*: A collaborative musical instrument}},
year = {2006}
}
@inproceedings{Schacher2016,
address = {Hamburg},
author = {Schacher, Jan and Bisig, Daniel and Neff, Patrck},
booktitle = {Proceedings of the Sound and Music Computing Conference},
pages = {407--414},
title = {{Exploring Gesturality in Music Performance}},
year = {2016}
}
@inproceedings{Madgwick2015,
abstract = {Clock synchronisation is a mature and important aspect of distributed computing systems. Despite the importance of accurate timing in music, there are relatively few widely applicable synchronisation solutions available to computer music practitioners. In this paper we present a simple OSC-based synchronisation method for wired and wireless applications, which is designed to be easy to apply and is shown to offer accuracy appropriate for fine-grained music applications. The proposed solution relies on a single master sending a synchronisation message to all slaves. Empirical studies with a heterogeneous network of 17 Wi-Fi slaves and 5 Ethernet slaves demonstrate that each homogeneous group is able to achieve a relative synchronisation accuracy of 166 us and 100 us respectively, offset from the master time by their respective network latencies. An acoustic localisation system is implemented to demonstrate an application that requires both accurate synchronisation and benefits from wireless connectivity. The system is shown to precisely locate a sound source with a standard deviation of 1.8 mm.},
address = {Denton},
author = {Madgwick, Sebastian and Barreto, Carlos and Mitchell, Thomas and Freed, Adrian},
booktitle = {Proceedings of the International Computer Music Conference},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Madgwick et al. - 2015 - Simple Synchronisation for Open Sound Control.pdf.pdf:pdf},
isbn = {0984527443},
keywords = {Network Time Synchronisation},
mendeley-tags = {Network Time Synchronisation},
pages = {218--224},
title = {{Simple Synchronisation for Open Sound Control.pdf}},
year = {2015}
}
@book{Mayring2002,
address = {Weinheim / Basel},
author = {Mayring, Philipp},
title = {{Einf{\"{u}}hrung in die qualitative Sozialforschung}},
year = {2002}
}
@article{Blades2012,
abstract = {This paper assesses the impact of the Choreographic Language Agent and the Digital Dance Archives on dance ontology. Enhanced visualisation - afforded by digital technology – impacts on the essential ontological features of dance, such as ephememerality and the human body. Referring to the work of Nelson Goodman (1968) and Martin Heidegger (1977), I discuss the significance of creative programming for dance, asking what such tools reveal about the ontology of the form and existing concepts of movement, notation and embodiment.},
author = {Blades, Hetty},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Blades - 2012 - Creative Computing and the Re-Configuration of Dance Ontology.pdf:pdf},
journal = {Proceedings of Electronic Visualization in the Arts (EVA 2012)},
pages = {221--228},
title = {{Creative Computing and the Re-Configuration of Dance Ontology}},
year = {2012}
}
@article{Kim-Boyle2014,
author = {Kim-Boyle, David},
doi = {10.1017/S1355771814000272},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Kim-Boyle - 2014 - Visual Design of Real-Time Screen Scores.pdf:pdf},
issn = {1355-7718},
journal = {Organised Sound},
keywords = {Realtime Notation,screen scores,ual design of real-time},
mendeley-tags = {Realtime Notation},
number = {03},
pages = {286--294},
title = {{Visual Design of Real-Time Screen Scores}},
url = {http://www.journals.cambridge.org/abstract{\_}S1355771814000272},
volume = {19},
year = {2014}
}
@incollection{Swift2013a,
abstract = {Improvisational group music-making, informally known as ‘jamming', has its own cultures and conventions of musical interaction. One characteristic of this interaction is the primacy of the experience over the musical artefact—in some sense the sound created is not as important as the feeling of being ‘in the groove'. As computing devices infiltrate creative, open-ended task domains, what can HumanComputer Interaction (HCI) learn from jamming? How do we design systems where the goal is not an artefact but a felt experience? This chapter examines these issues in light of an experiment involving ‘Viscotheque', a novel group music-making environment based on the iPhone.},
author = {Swift, Ben},
booktitle = {Music and Human-Computer Interaction},
doi = {10.1007/978-1-4471-2990-5},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Swift - 2013 - Chasing a Feeling Experience in Computer Supported Jamming.pdf:pdf},
isbn = {978-1-4471-2989-9},
pages = {85--99},
title = {{Chasing a Feeling: Experience in Computer Supported Jamming}},
url = {http://link.springer.com/10.1007/978-1-4471-2990-5},
year = {2013}
}
@inproceedings{Narveson2013,
address = {Stockholm},
author = {Narveson, Jascha and Trueman, Dan},
booktitle = {Proceedings of the Sound and Music Computing Conference},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Narveson, Trueman - 2013 - LANdini a networking utility for wireless LAN-based laptop ensembles.pdf:pdf},
keywords = {Problems with OSC communication over wireless rout,Time Synchronisation,and data from tests is presented. Future improveme},
mendeley-tags = {Time Synchronisation},
pages = {309--316},
title = {{LANdini : a networking utility for wireless LAN-based laptop ensembles}},
url = {http://www.logos-verlag.de/cgi-bin/buch/isbn/3472},
year = {2013}
}
@inproceedings{Bisig2017,
address = {Lissabon},
author = {Bisig, Daniel},
booktitle = {Proceedings of the Conference on Computation, Communication, Aesthetics {\&} X},
pages = {submitted},
title = {{Watchers – An Installative Representation of a Sound Synthesis System}},
year = {2017}
}
@article{Cadoz2000,
abstract = {In this article, we comment on various definitions of the term gesture in the general literature of human- human and human-computer interaction and in the musica domain. Different propositions of gesture classifications are then discussed and topics from other disciplines, that are important to the discussion on gesture and music, are presented. Concepts developed by the first author related to instrumental gestures, such as energy continuum, gestural channel, and instrumental gesture typology are reviewed in this context. The introduction of case studies on acoustic instruments helps in supporting the theory. Finally, the role of non-obvious (ancillary or accompanist) gestures is discussed with respect to clarinet playing.},
author = {Cadoz, Claude and Wanderley, Marcelo M.},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Cadoz, Wanderley - 2000 - Gesture-music.pdf:pdf},
isbn = {284426039X 9782844260390},
journal = {Trends in gestural control of music},
pages = {71--94},
title = {{Gesture-music}},
url = {http://www.music.mcgill.ca/{~}mwanderley/Trends/Trends{\_}in{\_}Gestural{\_}Control{\_}of{\_}Music/DOS/P.CadWan.pdf},
year = {2000}
}
@inproceedings{Kocher2017a,
address = {Helsinki},
author = {Kocher, Philippe},
booktitle = {Proceedings of Sound and Music Computing Conference},
pages = {submitted},
title = {{Technology-Assisted Performance of Polytemporal Music}},
year = {2017}
}
@inproceedings{El-shimy2015,
abstract = {This paper presents EmbodiNet, a novel system that aug- ments distributed performance with dynamic, real-time, hands-free control over several aspects of the musicians' sound, enabling them to seamlessly change volume, affect reverb and adjust their mix. Musi- cal performance is a demanding activity necessitating multiple lev- els of communication among its participants, as well as a certain degree of creativity, playfulness and spontaneity. As a result, distrib- uted musical performance presents a challenging application area for the “same time/different place” category of Computer-Supported Cooper- ative Work (CSCW). In fact, musicians wishing to play together over a network are typically limited by tools that differ little from standard videoconferencing. Instead, we propose leveraging the technology inher- ent to the distributed context towards meaningfully augmenting collabo- rative performance. In order to do so without introducing new paradigms that may require learning or that may distract musicians from their pri- mary task, we have designed and evaluated embodied controls that cap- italize on existing interpersonal interactions. Further designed to restore the spatial properties of sound that are typically absent in the distributed context, and apply the notion of “shared space” found in CSCW research, EmbodiNet also helps confer a greater level of co-presence than standard distributed performance systems. This paper describes the implementa- tion of EmbodiNet, along with the results of a long-term collaboration and experiment with a three-piece band. The long-term collaboration helped illustrate the benefits of augmenting an artistic form of distrib- uted collaboration, and resulted in a system that not only helped enhance our users' sense of enjoyment and self-expression, but one that they would also likely use in the future.},
author = {El-shimy, Dalia and Cooperstock, Jeremy R},
booktitle = {INTERACT 2015, Part II},
doi = {10.1007/978-3-319-22701-6},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/El-shimy, Cooperstock - 2015 - EmbodiNet Enriching Distributed Musical Collaboration Through Embodied Interactions.pdf:pdf},
isbn = {978-3-319-22700-9},
issn = {16113349},
pages = {1--19},
pmid = {4520227},
publisher = {Springer},
title = {{EmbodiNet: Enriching Distributed Musical Collaboration Through Embodied Interactions}},
url = {http://link.springer.com/10.1007/978-3-319-22701-6},
year = {2015}
}
@book{Hiekel2012,
address = {Kassel},
editor = {Hiekel, J{\"{o}}rn Peter and Utz, Christian},
title = {{Lexikon Neue Musik}},
year = {2012}
}
@article{Levisohn2011,
abstract = {This paper advocates for supporting movement awareness in ubiquitous computing as ameans of transforming technology design through an approach that considers movement as an exper-iential component of interaction rather than a solely functional one. Somatic awareness, or theawareness of the body from the inside, is one of the primary components of movement experience, yet its resource for technology design is not yet fully understood within the eld of Human-Computer In-teraction(HCI).Theinclusionofphenomenologicalmovementexperienceincomputationalinteractionhas the potential to improve user experience, enhance the delity and quality of communication, and  produce heightened engagement for users. Although somatic awareness has received little attentionwithin HCI, other disciplines offer theories and frameworks that can inform the development of tech-nologytosupportmovementawareness.Throughthediscussionoftheoriesofembodimentfromadiverserange of disciplines including cognitive science, dance, somatic practices, and philosophy, this paper  presents an argument for the importance of movement experience as a component of interaction withtechnology. It provides a history of movement within HCI, highlighting movement's role in a varietyof theories and frameworks, and identies two distinct approaches toward the utilization of movement in HCI— task oriented and experience-oriented. An in-depth discussion of experience-oriented ap- proaches illustrates the importance of movement and somatic awareness as necessary components of  ubiquitous computing systems.},
author = {Levisohn, Aaron and Schiphorst, Thecla},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Levisohn, Schiphorst - 2011 - Embodied engagement supporting movement awareness in ubiquitous computing systems.pdf:pdf},
isbn = {Levisohn, Aaron and Schiphorst, Thecla  (2011) Embodied engagement: supporting movement awareness in ubiquitous computing systems.  Ubiquitous Learning: An International Journal, 3.  pp. 97-111.  ISSN 1835-9795},
issn = {1835-9795},
journal = {Ubiquitous Learning: An International Journal},
keywords = {awareness,design,embodiment,engagement,experience,movement,phenomenology,somatics,ubiquitous computing},
number = {4},
pages = {97--111},
title = {{Embodied engagement: supporting movement awareness in ubiquitous computing systems}},
url = {http://ijq.cgpublisher.com/product/pub.186/prod.151{\%}5Cnhttp://eprints.iat.sfu.ca/1087/{\%}5Cnhttp://eprints.iat.sfu.ca/1087/1/aaronlevisohn.com{\_}PDF{\_}Embodied Engagement.pdf},
volume = {3},
year = {2011}
}
@article{Hunt2002,
abstract = {This paper considers the issues involved in the design of electronic and computer interfaces, specifically mapping – the designed link between an instrument's playing interface and its sound source. It defines the problem area, reviews the literature, and gives examples of specific system mappings. A general model is presented, with the aim of providing a framework for future discussions on what makes an effective mapping. Several guidelines for mapping strategies are given, based on existing work.},
author = {Hunt, Andy and Wanderley, Marcelo M.},
doi = {10.1017/S1355771802002030},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Hunt, Wanderley - 2002 - Mapping performer parameters to synthesis engines.pdf:pdf},
issn = {1355-7718},
journal = {Organised Sound},
number = {02},
pages = {97--108},
publisher = {Zurcher Fachhochschule},
title = {{Mapping performer parameters to synthesis engines}},
volume = {7},
year = {2002}
}
@inproceedings{Baalman2010a,
abstract = {SenseStage is a research-creation project to develop a wireless sensor network infrastructure for live performance and interactive, real-time environments. The project is motivated by the economic and technical constraints of live performance contexts and the lack of existing tools for artistic work with wireless sensing platforms. The development is situated within professional artistic contexts and tested in real world scenarios. In this paper we discuss our choice of wireless platform, the design of the hardware and firmware, battery options, and an evaluation of the data transmission quality within the wireless network. Additionally, software integration of the wireless platform with popular media programming environments is addressed, as well as evaluation and dissemination of the technology through workshops. Finally, we elaborate on the application of the hardware and software infrastructure in professional artistic projects: two dance performances, two media projects involving environmental data and an interactive, multi-sensory installation.},
author = {Baalman, Marije A J and Belleval, Vincent De and Salter, Christopher L and Malloch, Joseph and Thibodeau, Joseph and Wanderley, Marcelo M.},
booktitle = {Proceedings of International Computer Music Conference},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Baalman et al. - 2010 - Sense Stage - Low Cost , Open Source Wireless Sensor Infrastructure for Live Performance and Interactive , Real.pdf:pdf},
isbn = {0971319286},
pages = {242--249},
title = {{Sense / Stage - Low Cost , Open Source Wireless Sensor Infrastructure for Live Performance and Interactive , Real-Time Environments}},
year = {2010}
}
@inproceedings{Visser2015,
abstract = {This paper is about the streaming of a live-performance to a local audience. The audience is invited to connect to a wireless stream using their personal mobile devices like smartphones and tablets as remote loudspeakers. In this way the streamed audio will be spatialized by the mobile devices and the participating audience thus become part of the performance. Such a setup was explored in several live-performances of a group of composers-musicians called Die Neukoms. The performers strive to augment the impression of liveness when performing electro-acoustic music, and at the same time probe into alternative performer-listener relationships. Therefore they explore the effect of spatialization and the diffusion in time of the audio stream using personal mobile devices. By involving the audience in the process of the performance, this also ruptures the classical performers-listeners paradigm.},
address = {New York},
author = {Visser, Jeroen and Vogtenhuber, Raimund},
booktitle = {ACM International Conference Proceeding Series},
doi = {10.1145/2814895.2814904},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Visser, Vogtenhuber - 2015 - Die Neukoms. Local streamed live-performance with mobile devices.pdf:pdf},
isbn = {9781450338967 | 9781450338967},
keywords = {audience participating,audio diffusion,audio streaming,electroacoustic performance,liveness,network-music,social music,spatialization},
publisher = {ACM Press},
title = {{Die Neukoms. Local streamed live-performance with mobile devices}},
year = {2015}
}
@book{Brooks2011,
booktitle = {Arts and Technology},
doi = {10.1007/978-3-642-27317-9_36},
editor = {Brooks, Anthony L.},
file = {:C$\backslash$:/Users/sschies1/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2011 - Lecture Notes of the Institute for Computer Sciences , Social Informatics and Telecommunications Engineering.pdf:pdf},
isbn = {9783642118692},
issn = {18678211},
pages = {205},
publisher = {Springer},
title = {{Lecture Notes of the Institute for Computer Sciences , Social Informatics and Telecommunications Engineering}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=JPGHx{\_}Avl4AC{\&}oi=fnd{\&}pg=PP2{\&}dq=Lecture+Notes+of+the+Institute+for+Computer+Sciences+,+Social+Informatics+and+Telecommunications+Engineering{\&}ots=cYHmwWwgwy{\&}sig=vqoQa9dVtQP1wFEklhx4p3OZru},
year = {2011}
}
@article{Wanderley1999,
abstract = {This paper deals with the gestural language of instrumen- talists playing wind instruments. It discusses the role of non-obvious performer gestures that may nevertheless influence the final sound pro- duced by the acoustic instrument. These gestures have not commonly been considered in sound synthesis, although they are an integral part of the instrumentalist's full gestural language. The structure of this pa- per will be based on an analysis of these non-obvious gestures followed by some comments on how to best classify them according to existing research on gesture reviewed in the introduction; finally, the influence of these gestures on the sound produced by the instrument will be studied and measurement and simulation results presented.},
author = {Wanderley, Marcelo M.},
doi = {10.1007/3-540-46616-9_3},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Wanderley - 1999 - Non-obvious performer gestures in instrumental music.pdf:pdf},
isbn = {3540669353},
issn = {16113349},
journal = {Lecture Notes in Computer Science},
pages = {37--48},
title = {{Non-obvious performer gestures in instrumental music}},
volume = {1739},
year = {1999}
}
@article{Hajdu2010,
abstract = {This article presents aspects of notation in projects employing the Quintet.net networked performance environment. As Quintet.net—to our knowledge, the first networked music environment utilizing real-time notation—was conceived in 1999, we will be reviewing ten years of practice in a number of scenarios. After the historical overview, we shall give a description of the current implementation of music notation in separate layers dedicated to specific tasks such as standard notation, graphic notation, performance notation and score annotation. The article then proceeds to the analysis of individual pieces composed by members of the European Bridges Ensemble and concludes with an outlook on future perspectives.},
author = {Hajdu, Georg and Niggemann, Kai and Siska, {\'{A}}d{\'{a}}m and Szigetv{\'{a}}ri, Andrea},
doi = {10.1080/07494467.2010.509592},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Hajdu et al. - 2010 - Notation in the Context of Quintet.net Projects.pdf:pdf},
journal = {Contemporary Music Review},
keywords = {Electronic Music Performance Introduction,Max/Msp,Multimedia,Music Notation,Network Music Performance,Networked Music Practice,Realtime Composition,Realtime Notation},
mendeley-tags = {Networked Music Practice,Realtime Notation},
number = {1},
pages = {39--53},
title = {{Notation in the Context of Quintet.net Projects}},
volume = {29},
year = {2010}
}
@book{Holland2013,
abstract = {This agenda-setting book presents state of the art research in Music and Human-Computer Interaction (also known as 'Music Interaction'). Music Interaction research is at an exciting and formative stage. Topics discussed include interactive music systems, digital and virtual musical instruments, theories, methodologies and technologies for Music Interaction. Musical activities covered include composition, performance, improvisation, analysis, live coding, and collaborative music making. Innovative approaches to existing musical activities are explored, as well as tools that make new kinds of musical activity possible. Music and Human-Computer Interaction is stimulating reading for professionals and enthusiasts alike: researchers, musicians, interactive music system designers, music software developers, educators, and those seeking deeper involvement in music interaction. It presents the very latest research, discusses fundamental ideas, and identifies key issues and directions for future work.},
author = {Holland, Simon},
booktitle = {Springer series on cultural computing},
doi = {10.1007/978-1-4471-2990-5},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Holland - 2013 - Music and human-computer interaction.pdf:pdf},
isbn = {9781447129905 (electronic bk.)$\backslash$n1447129903 (electronic bk.)},
keywords = {Electronic books.,Human-computer interaction.,Music Social aspects.,Music Technological innovations.},
pages = {1 online resource.},
title = {{Music and human-computer interaction}},
url = {http://dx.doi.org/10.1007/978-1-4471-2990-5},
year = {2013}
}
@inproceedings{Marshall2006,
abstract = {This paper discusses vibrotactile feedback in digital musical instruments. It compares the availability of intrinsic vibrotactile feedback in traditional acoustic musical instruments with the lack of vibrotactile feedback in most digital musical instruments. A short description of human sensory ability with regard to this form of feedback is given and the usefullness of vibrotactile feedback to musical performers is also briefly discussed. A number of devices are examined which can be used to provide vibrotactile feedback in a digital musical instruments and some experiments to evaluate these devices are also described. Finally, examples are given of a number of instruments which make use of some of these devices to provide vibrotactile feedback to the performer.},
author = {Marshall, Mark T. and Wanderley, Marcelo M.},
booktitle = {New Interfaces for Musical Expression (NIME)},
doi = {10.1.1.128.1976},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Marshall, Wanderley - 2006 - Vibrotactile feedback in digital musical instruments.pdf:pdf},
isbn = {2844263143},
issn = {2-84426-314-3},
keywords = {digital musical instruments,tactile feedback,vibro-tactile feedback},
pages = {226--229},
title = {{Vibrotactile feedback in digital musical instruments}},
year = {2006}
}
@article{Weitzner2012,
author = {Weitzner, Nathan},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Weitzner - 2012 - massMobile–an audience participation framework.pdf:pdf},
journal = {Proceedings of the {\ldots}},
title = {{massMobile–an audience participation framework}},
url = {http://distributedmusic.gatech.edu/sandvox/publications/pdf{\_}files{\_}of{\_}publications/massmobile.pdf},
year = {2012}
}
@inproceedings{OModhrain2000,
abstract = {In this paper, we test the hypothesis proposed in a companion paper submitted to this conference (see [SS00]), namely that the playability of a bow stroke can be fully described by three parameters - bow velocity, bow position and bow force. Moreover, the envelope of these parameters influences the quality of the attack. In this paper, we present a novel technique for measuring parameters of bowing. By coupling ahaptic display to acomputational model of abowed string, wesimulate the normal and frictional forces present},
author = {O'Modhrain, Sile and Serafin, Stefania and Chafe, Chris and Smith, Julius O.},
booktitle = {International Computer Music Conference (ICMC)},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/O'Modhrain et al. - 2000 - Influence of attack parameters on the playability of a virtual bowed string instrument tuning the model.pdf:pdf},
title = {{Influence of attack parameters on the playability of a virtual bowed string instrument: tuning the model}},
year = {2000}
}
@inproceedings{Kocher2016a,
abstract = {This paper approaches the idea of a musical work whose polyvalent form is constituted by its randomly generated tempo structure. For this kind of music the original concept of 'open form' is extended by the use of a computer algorithm that not only generates an aleatory collage of prepared fragments, but also calculates an appropriate tempo progression to arrange and overlap these fragments in a musically meaningful way. The author's collaboration with a chamber music trio is presented and the artistic strategies and technical implementations are discussed.},
address = {Florence},
author = {Kocher, Philippe},
booktitle = {Proceedings of the Generative Art Conference},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Kocher - 2016 - Rethinking 'Open Form'.pdf:pdf},
keywords = {algorithmic composition,mobile score,open form,tempo polyphony},
pages = {339--349},
publisher = {Domus Argenia Publisher},
title = {{Rethinking 'Open Form'}},
year = {2016}
}
@inproceedings{Fels2004,
abstract = {The Tooka was created as an exploration of two personinstruments. We have worked with two Tooka performers toenhance the original experimental device to make a musicalinstrument played and enjoyed by them. The main additions tothe device include: an additional button that behaves as amusic capture button, a bend sensor, an additional thumbactuated pressure sensor for vibrato, additional musicalmapping strategies, and new interfacing hardware. Thesedevelopments a rose through exper iences andrecommendations from the musicians playing it. In addition tothe changes to the Tooka, this paper describes the learningprocess and experiences of the musicians performing with theTooka.},
address = {Hamamatsu, Japan},
author = {Fels, Sidney S and Kaastra, Linda and Takahashi, Sachiyo and Mccaig, Graeme},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
editor = {Nagashima, Yoichi and Ito, Yasuo and Furuta, Yuji},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Fels et al. - 2004 - Evolving Tooka from Experiment to Instrument.pdf:pdf},
keywords = {Musician-centred design,two-person musical instrument.},
pages = {1--6},
title = {{Evolving Tooka: from Experiment to Instrument}},
url = {http://www.nime.org/proceedings/2004/nime2004{\_}001.pdf},
year = {2004}
}
@book{Lamnek2005,
address = {Weinheim},
author = {Lamnek, Siegfried},
title = {{Qualitative Sozialforschung}},
year = {2005}
}
@article{Wang2014,
abstract = {The Mobile Phone Orchestra (MoPhO) is a repertoire-based ensemble that uses mobile phones as the primary musical instrument. While mobile phones have been used for artistic expression before, MoPhO is the fi rst ensemble of its kind and scale, employing more than a dozen players and mobile phones that serve as compositional, research, performance, and educational platforms. MoPhO was founded in Fall 2007 at Stanford University's Center for Computer Research in Music and Acoustics (CCRMA) and per- formed its debut concert in January 2008. Since then it has spawned new ensembles at the University of Michigan, as well as in Berlin and Helsinki, and has performed in Genoa, Belfast, Helsinki, San Francisco, and Berlin. We chronicle the motivation and the process of creating such an ensemble and the repertoire of MoPhO's first perfor- mances. MoPhO aims to demonstrate that mobile phone orchestras are exciting techno- logical and artistic opportunities for new types of music-making (Figure 18.1). Mobile phones are growing in sheer numbers and computational power. Hyper-ubiquitous and deeply entrenched in the lifestyles of people around the world, they transcend cultural and economic barriers that other general computing devices such as laptops have failed to penetrate. Computationally, the mobile phones of today off er speed and storage capabilities comparable to desktop computers from less than ten years ago, rendering them suitable for real-time sound synthesis/analysis and other musical applications. Like traditional acoustic instruments, mobile phones are intimate sound producing devices. Th ese devices also have the advantages of strength in num- bers and ultramobility, making them attractive for holding jam sessions, rehearsals, and even performances in both formal as well as ad hoc settings. A goal of MoPhO is to explore these possibilities as a research and music-making environment, fusing techno- logical artifact and human musicianship. Th e notion of a mobile phone orchestra bears many similarities with that of a lap- top orchestra. Th e idea of phones as intimate sound sources leads to our notion of “mobile electronic chamber music.” MoPhO presents a well-defined context for researchers and composers to craſt new music tailored to mobile instruments and ensembles. As in the laptop orchestra, the combination of technology, aesthetics, and instrument building presents a powerful pedagogical opportunity. At the same time, the mobile phone orchestra is diff erenti- ated by its unique limitations (i.e., computational power) and opportunities, such as its extreme mobility and potential for wide-area social interactions.},
author = {Wang, Ge and Essl, Georg and Penttinen, Henri},
doi = {10.1093/oxfordhb/9780199913657.013.018},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Wang, Essl, Penttinen - 2014 - The Mobile Phone Orchestra.pdf:pdf},
isbn = {9780199913657},
journal = {The Oxford Handbook of Mobile Music Studies},
keywords = {CCRMA,MoPhO,Stanford University,mobile phones,music-making,repertoire-based ensemble},
number = {August},
pages = {453--469},
title = {{The Mobile Phone Orchestra}},
volume = {2},
year = {2014}
}
@inproceedings{Todoroff2011,
author = {Todoroff, Todor},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Todoroff - 2011 - Wireless Digital Analog Sensors for Music and Dance Performances.pdf:pdf},
keywords = {wireless marg sensors},
number = {June},
pages = {515--518},
title = {{Wireless Digital/Analog Sensors for Music and Dance Performances}},
year = {2011}
}
@article{Hirabayashi2015,
annote = {mobile phones, audience participation},
author = {Hirabayashi, Masami and Eshima, Kazuomi},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Hirabayashi, Eshima - 2015 - Sense of Space The Audience Participation Music Performance with High-Frequency Sound ID.pdf:pdf},
journal = {Proceedings of the International Conference on New Interfaces for Musical Expression},
keywords = {audience participation,music performance,sound id},
pages = {58--60},
title = {{Sense of Space : The Audience Participation Music Performance with High-Frequency Sound ID}},
year = {2015}
}
@inproceedings{Madgewick2013,
author = {Madgewick, Sebastian and Mitchell, Thomas},
booktitle = {SMC Sound and Music Computing Conference},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Madgwick, Mitchell - 2013 - x-OSC - A versatile wireless I O device for creative music applications.pdf.pdf:pdf},
isbn = {978-3-8325-3472-1},
title = {{x-OSC - A versatile wireless I O device for creative music applications.pdf}},
year = {2013}
}
@article{Wanderley2004,
annote = {NULL},
author = {Wanderley, Marcelo M. and Depalle, Philippe},
doi = {10.1109/JPROC.2004.825882},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Wanderley, Depalle - 2004 - Gestural Control of Sound Synthesis.pdf:pdf},
issn = {0018-9219},
journal = {Proceedings of the IEEE},
keywords = {AHMI,audio systems,music,signal synthesis,user inter-},
mendeley-tags = {AHMI},
number = {4},
pages = {632--644},
title = {{Gestural Control of Sound Synthesis}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1278687},
volume = {92},
year = {2004}
}
@book{Dixon2007,
address = {Cambridge},
annote = {NULL},
author = {Dixon, Steve},
publisher = {MIT Press},
title = {{Digital Performance. A History of New Media in Theater, Dance, Performance Art, and Installation}},
year = {2007}
}
@book{DelaMotte2000a,
address = {Laaber},
editor = {de la Motte, Helga},
publisher = {Laaber-Verlag},
title = {{Geschichte der Musik im 20. Jahrhundert 1975-2000}},
year = {2000}
}
@incollection{Bouwer2013,
abstract = {Tonal Harmony is widely considered to be the most technical and complex part of music theory. Consequently harmonic skills can be hard to acquire. Furthermore, experience of the flexible manipulation of harmony in real time generally requires the ability to play an instrument. Even for those with instrumental skills, it can be difficult to gain clear insight into harmonic abstractions. The above state of affairs gives rise to substantial barriers not only for beginners but also for many experienced musicians. To address these problems, Harmony Space is an interactive digital music system designed to give insight into a wide range of musical tasks in tonal harmony, ranging from performance and composition to analysis. Harmony Space employs a principled set of spatial mappings to offer fluid, precise, intuitive control of harmony. These mappings give rise to sensorymotor and music-theoretic affordances that are hard to obtain in any other way. As a result, harmonic abstractions are rendered amenable to concrete, visible control by simple spatial manipulation. In the language of conceptual metaphor theory, many relationships in tonal harmony become accessible to rapid, universal, low-level, robust human inference mechanisms using image schemata such as containment, contact, centre-periphery, and source-path-goal. This process is more rapid, and imposes far less cognitive load, than slow, abstract symbolic reasoning. Using the above principles, several versions of Harmony Space have been designed to exploit specific interaction styles for different purposes. We note some key variants, such as the desktop version, the camera tracked version, while focusing principally on the most recent version, Song Walker, which employs whole body interaction. Preliminary results from a study of the Song Walker system are outlined, in which both beginners and expert musicians undertook a range of musical tasks involving the performance, composition and analysis of music. Finally, we offer a discussion of the limitations of the current system, and outline directions for future work.},
author = {Bouwer, Anders and Holland, Simon and Dalgleish, Mat},
booktitle = {Music and Human-Computer Interaction},
doi = {10.1007/978-1-4471-2990-5},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Bouwer, Holland, Dalgleish - 2013 - Song Walker Harmony Space Embodied Interaction Design for Complex Musical Skills.pdf:pdf},
isbn = {978-1-4471-2989-9},
pages = {207--221},
title = {{Song Walker Harmony Space: Embodied Interaction Design for Complex Musical Skills}},
url = {http://link.springer.com/10.1007/978-1-4471-2990-5},
year = {2013}
}
@inproceedings{Vickery2015,
abstract = {This paper discusses two pilot studies conducted by Lindsay Vickery and Talisha Goh, "Screening the Score: Exploring the Potentials and Limitations of Presenting Music Notation on the iPad" and "Sight-Reading Polyphonic Music Musical Textures: a Pilot Eye-Movement Study". Vickery's experiment sought to investigate the activity of the eyes of musicians while performing a variety of notations and score presentation types from a screen. Goh's experiment explored sight-reading polyphonic keyboard music containing two, three, four and five voices, at a comfortable pace and with a click-track beat.},
author = {Vickery, Lindsay and Goh, Talisha},
booktitle = {Proceedings of the Australasian Computer Music Association},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Vickery, Goh - 2015 - MUSIC SCREEN-READING indicative results from two pilot studies.pdf:pdf},
keywords = {Realtime Notation,iPad},
mendeley-tags = {Realtime Notation,iPad},
pages = {199--125},
title = {{MUSIC SCREEN-READING : indicative results from two pilot studies}},
year = {2015}
}
@inproceedings{Tanaka2010,
abstract = {This paper reviews and extends questions of the scope of an interactive musical instrument and mapping strategies for expressive performance. We apply notions of embodiment and affordance to characterize gestural instruments. We note that the democratization of sensor technology in consumer devices has extended the cultural contexts for interaction. We revisit questions of mapping drawing upon the theory of affordances to consider mapping and instrument together. This is applied to recent work by the author and his collaborators in the development of instruments based on mobile devices designed for specific performance situations},
author = {Tanaka, Atau},
booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression (NIME)},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Tanaka - 2010 - Mapping Out Instruments, Affordances, and Mobiles.pdf:pdf},
pages = {15--18},
title = {{Mapping Out Instruments, Affordances, and Mobiles}},
url = {http://www.nime.org/proceedings/2010/nime2010{\_}088.pdf},
year = {2010}
}
@article{Jarvelainen2013,
author = {J{\"{a}}rvel{\"{a}}inen, Hanna and Papetti, Stefano and Schiesser, S{\'{e}}bastien and Grosshauser, Tobias},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/J{\"{a}}rvel{\"{a}}inen et al. - 2013 - Audio-Tactile Feedback in Musical Gesture Primitives Finger Pressing(2).pdf:pdf},
isbn = {978-3-8325-3472-1},
journal = {Sound and Music Computing (SMC)},
number = {March 2014},
pages = {109--114},
title = {{Audio-Tactile Feedback in Musical Gesture Primitives: Finger Pressing}},
url = {http://smcnetwork.org/system/files/AUDIO-TACTILE FEEDBACK IN MUSICAL GESTURE PRIMITIVES - FINGER PRESSING.pdf},
year = {2013}
}
@incollection{Bisig2012a,
address = {Berlin},
author = {Bisig, Daniel},
booktitle = {Verk{\"{o}}rperungen},
editor = {Blum, Andr{\'{e}} Louis and Krois, John Michael and Rheinberger, Hans-J{\"{o}}rg},
publisher = {Akademie Verlag},
title = {{Kunst und k{\"{u}}nstliches Leben}},
year = {2012}
}
@article{Bench2004,
author = {Bench, Harmony},
journal = {Extensions: The Online Journal of Embodied Technology},
title = {{Virtual Embodiment and the Materiality of Images}},
volume = {1},
year = {2004}
}
@article{Wessel2002,
abstract = {When asked what musical instrument they play, few computer musicians respond spontaneously with ‘‘I play the computer.'' Why not? In this re- port, we examine the problems associated with the notion of the computer as musical instrument and the prospects for their solution. We begin with a discussion of our goals and re- quirements for computer-based musical instru- ments, raising the main issues that inform our work. Then we discuss a variety of metaphors for musical control that we have found to be powerful. Finally, we discuss some of the technology we have developed for implementing these instruments.},
author = {Wessel, David and Wright, Matthew},
doi = {10.1162/014892602320582945},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Wessel, Wright - 2002 - Problems and Prospects for Intimate Musical Control of Computers.pdf:pdf},
isbn = {0148926023205},
issn = {0148-9267},
journal = {Computer Music journal},
keywords = {communications protocols,gestural controllers,latency,musical,reactive computing,signal processing},
number = {3},
pages = {11--14},
title = {{Problems and Prospects for Intimate Musical Control of Computers}},
url = {http://www.nime.org/proceedings/2001/nime2001{\_}011.pdf},
volume = {26},
year = {2002}
}
@article{Magnusson2010,
abstract = {This paper investigates two central terms in Human Computer Interaction (HCI) – affordances and constraints – and studies their relevance to the design and understanding of digital musical systems. It argues that in the analysis of complex systems, such as new interfaces for musical expression (NIME), constraints are a more productive analytical tool than the common HCI usage of affordances. Constraints are seen as limitations enabling the musician to encapsulate a specific search space of both physical and compositional gestures, proscribing complexity in favor of a relatively simple set of rules that engender creativity. By exploring the design of three different digital musical systems, the paper defines constraints as a core attribute of mapping, whether in instruments or compositional systems. The paper describes the aspiration for designing constraints as twofold: to save time, as musical performance is typically a real-time process, and to minimize the performer's cognitive load. Finally, it discusses skill and virtuosity in the realm of new musical interfaces for musical expression with regard to constraints.},
author = {Magnusson, Thor},
doi = {10.1162/COMJ_a_00026},
issn = {0148-9267},
journal = {Computer Music Journal},
keywords = {J930 Audio Technology,W280 Interactive and Electronic Design,W300 Music},
number = {4},
pages = {62--74},
title = {{Designing constraints: composing and performing with digital musical systems}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/COMJ{\_}a{\_}00026},
volume = {34},
year = {2010}
}
@incollection{McDermott2013,
abstract = {A fundamental assumption in the fields of human-computer interaction and usability studies is that interfaces should be designed for ease of use, with a few exceptions such as the trade-off with long-term power. In this chapter it is argued that in music interaction the situation is far more complex, with social, technical, artistic, and psychological reasons why difficulty is in some cases a good thing, and in other cases a necessary evil. Different aspects of static and time-varying difficulty in music interaction are categorised. Some specific areas in which difficulty seems to be inextricably linked to positive aspects of music interaction are described. This is followed by discussion of some areas inwhich difficulty is undesirable and, perhaps, avoidable. Examples are drawn frommusic interaction research in general and from other chapters of this book in particular.},
author = {McDermott, James and Gifford, Toby and Bouwer, Anders and Wagy, Mark},
booktitle = {Music and Human-Computer Interaction},
chapter = {2},
doi = {10.1007/978-1-4471-2990-5},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/McDermott et al. - 2013 - ShouldMusic Interaction Be Easy.pdf:pdf},
isbn = {978-1-4471-2989-9},
pages = {29--47},
title = {{ShouldMusic Interaction Be Easy?}},
url = {http://link.springer.com/10.1007/978-1-4471-2990-5},
year = {2013}
}
@inproceedings{McKinney2012,
abstract = {Approaches to network music performance are often fo- cused on creating systems with minimal latency and maxi- mal synchronicity. In this article we present Yig, the Father of Serpents, a new program for performing network music that is designed with these principles in mind, but also of- fers an argument for a different approach. In Yig, users may have identical states yet the audio rendering could be different. In this paper an introduction to the interface is followed by a brief description of the technical develop- ment of the software. Next, the instrument is classified and analyzed using existing frameworks and some philosophy behind divergence in network music is explained. The ar- ticle concludes with an numeration of potential software improvements and suggestions towards future work using divergence.},
author = {McKinney, C and Collins, Nick},
booktitle = {Proceedings of the 9th Sound and Music Computing Conference},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/McKinney, Collins - 2012 - Yig, the Father of Serpents A Real-Time Network Music Performance Environment.pdf:pdf},
isbn = {9783832531805},
pages = {101--106},
title = {{Yig, the Father of Serpents: A Real-Time Network Music Performance Environment}},
url = {http://smcnetwork.org/system/files/smc2012-212.pdf},
year = {2012}
}
@inproceedings{Tsui2014,
abstract = {This work presents a new platform for performing one-man orchestra (Figure 1). The conductor is the only human involved, who uses traditional bimanual conducting gestures to interactively direct the performance of smartphones instead of human performers in a real-world orchestra. Each smartphone acts as a virtual performer who plays a certain music instrument like piano and violin. Our work not only allows ordinary people to experience music conducting but also provides a training platform so that students can practice music conducting with a unique listening experience.},
author = {Tsui, C.K. and Law, C.H. and Fu, H.},
booktitle = {SIGGRAPH Asia 2014 Emerging Technologies, SA 2014},
doi = {10.1145/2669047.2669049},
isbn = {9781450319553},
title = {{One-man orchestra: Conducting smartphone orchestra}},
year = {2014}
}
@inproceedings{Kocher2014,
abstract = {This paper describes the current development of a system designed for the synchronization of musicians in polytempic music. In order to convey the tempo, an animation is used that resembles the gestures of a conductor, which is believed to be particularly comprehensible for musicians. This system offers an alternative to the use of a click track which is still the most common means for the purpose of synchronization. The possibility to combine several devices in a network allows for the synchronization of several players in ensemble music. It is hoped that this system promotes the creation and performance of music that exhibit ambitious tempo polyphony as well as spatial distribution of the musicians.},
address = {Athens},
author = {Kocher, Philippe},
booktitle = {Proceedings of the International Computer Music Conference},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Kocher - 2014 - Polytempo Network A System for Technology-Assisted Conducting.pdf:pdf},
keywords = {Mobile Score,Tempo Synchronisation},
mendeley-tags = {Mobile Score,Tempo Synchronisation},
pages = {532--535},
title = {{Polytempo Network: A System for Technology-Assisted Conducting}},
year = {2014}
}
@inproceedings{Bisig2013a,
address = {Daejeon},
author = {Bisig, Daniel and Schiesser, S{\'{e}}bastien},
booktitle = {Proceedings of the Conference on New Interfaces for Musical Expression},
title = {{Coral - a Physical and Haptic Extension of a Swarm Simulation}},
year = {2013}
}
@inproceedings{Hope2015,
abstract = {In 2012 Western Australian new music ensemble Decibel launched a commercially available score reader application (app) for the iPad, on the iTunes store. The Decibel ScorePlayer allows for network-synchronised scrolling of proportional colour music scores on multiple iPads. It is designed to facilitate the reading of scores featuring predominantly non-traditional notation in rehearsal and performance. The Decibel ScorePlayer has recently been further developed to include a range of new functions. These include new score models, enhanced instructions delivery, network communication based on the Open Sound Control (OSC) protocol and the ability to package audio playback as part of a score file and improved networking protocols. This paper discusses the evolution of these additions and the way they have been driven by, and adopted in, compositions and performances by the ensemble.},
author = {Hope, Cat and Wyatt, Aaron and Vickery, Lindsay},
booktitle = {Proceedings of the International Computer Music Conference},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Hope, Wyatt, Vickery - 2015 - The Decibel ScorePlayer New Developments and Improved Functionality.pdf:pdf},
keywords = {Mobile Score,Networked Music Practice,iPad},
mendeley-tags = {Mobile Score,Networked Music Practice,iPad},
pages = {314--317},
title = {{The Decibel ScorePlayer: New Developments and Improved Functionality}},
year = {2015}
}
@phdthesis{Mainsbridge2016,
author = {Mainsbridge, Mary},
file = {:C$\backslash$:/Users/sschies1/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mainsbridge - 2016 - Body as Instrument An Exploration of Gestural Interface Design.pdf:pdf},
school = {University of Technology Sydney},
title = {{Body as Instrument: An Exploration of Gestural Interface Design}},
year = {2016}
}
@article{Bevilacqua2011,
abstract = {Working in the interdisciplinary context at IRCAM (Institut de Recherche et Coordination Acoustique/Musique), the authors have developed, in collaboration with choreographers/composers/media artists, computer based gesture analysis and interactive audio processing systems that allows performers to control or interact with digital media—sound or video. This essay summarizes key elements of a lecture/demonstration on these tools and the paradigms central to their application. First, they categorize the different sensing systems typically found in dance contexts, in order to clarify what the term 'gesture capture' can encompass. In the second part, they provide examples of gesture sound controls often found in interactive dance performances.},
author = {Bevilacqua, Frederic and Schnell, Norbert and {Fdili Alaoui}, Sarah},
journal = {Emerging Bodies: The Performance of Worldmaking in Dance and Choreography},
pages = {183},
title = {{Gesture Capture : Paradigms in Interactive Music / Dance Systems}},
year = {2011}
}
@inproceedings{Turchet2016,
author = {Turchet, Luca and Mcpherson, Andrew},
booktitle = {Proceedings of the Sound and Music Computing Conference},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Turchet, Mcpherson - 2016 - Smart Instruments Towards an Ecosystem of Interoperable Devices Connecting Performers SMART INSTRUMENTS TO.pdf:pdf},
title = {{Smart Instruments: Towards an Ecosystem of Interoperable Devices Connecting Performers}},
year = {2016}
}
@article{Papetti2015,
abstract = {This paper describes the design of a hardware/software system for rendering multi-point, localized vibrotactile feedback in a multi-touch musical interface. A prototype was developed, based on the Madrona Labs Soundplane, which was chosen for it provides easy access to multi-touch data, including force, and its easily expandable layered construction. The proposed solution makes use of several piezo actuator discs, densely arranged in a honeycomb pattern on a thin PCB layer. Based on off-the-shelf components, custom amplifying and routing electronics were designed to drive each piezo element with standard audio signals. Features, as well as electronic and mechanical issues of the current prototype are discussed.},
author = {Papetti, Stefano and Schiesser, S{\'{e}}bastien and Fr{\"{o}}hlich, Martin},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Papetti, Schiesser, Fr{\"{o}}hlich - 2015 - Multi-point vibrotactile feedback for an expressive musical interface(2).pdf:pdf},
journal = {Proceedings of the International Conference on New Interfaces for Musical Expression},
number = {January},
pages = {235--240},
title = {{Multi-point vibrotactile feedback for an expressive musical interface}},
year = {2015}
}
@incollection{Gunduz2008,
abstract = {The papers in this volume reflect the debates that progressed during the 3rd Global Conference on Visions of Humanity in Cyberculture, Cyberspace and Science Fiction, held at Mansfield College, Oxford, United Kingdom in July 2008. The edited draft papers make up a snapshot output for actual publishing.},
author = {G{\"{u}}nd{\"{u}}z, Zeynep},
booktitle = {Humanity in Cibernetic Environments},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/G{\"{u}}nd{\"{u}}z - 2010 - Interactive Dance The Merger of Media Technologies and the Dancing Body. Visions of Humanity in Cyberculture, Cyberspace.pdf:pdf},
isbn = {9781904710714},
pages = {71--82},
title = {{Interactive Dance: The Merger of Media Technologies and the Dancing Body. Visions of Humanity in Cyberculture, Cyberspace, and Science Fiction}},
url = {https://www.academia.edu/358576/Humanity{\_}in{\_}Cybernetic{\_}Environments},
year = {2008}
}
@article{Mckinney2013,
author = {Mckinney, Chad and Val, As Paul and Collins, Nick},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Mckinney, Val, Collins - 2013 - Liveness in Network Music Performance.pdf:pdf},
title = {{Liveness in Network Music Performance}},
year = {2013}
}
@article{Barbosa2005,
abstract = {The Public Sound Objects (PSOs) project consists of the development of a networked musical system, which is an experimental framework to implement and test new concepts for online music communication. The PSOs project approaches the idea of collaborative musical performances over the Internet by aiming to go beyond the concept of using computer networks as a channel to connect performing spaces. This is achieved by exploring the internet's shared nature in order to provide a public musical space where anonymous users can meet and be found performing in collective sonic art pieces. The system itself is an interface-decoupled musical instrument, in which a remote user interface and a sound processing engine reside with different hosts in an extreme scenario where a user can access the synthesizer from any place in the world using the World Wide Web. Specific software features were implemented in order to reduce the disruptive effects of network latency, such as dynamic adaptation of the musical tempo to communication latency measured in real time and consistent sound panning with the object's behaviour at the graphical user interface. 1.},
author = {Barbosa, Alvaro},
doi = {10.1017/S135577180500097X},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Barbosa - 2005 - Public Sound Objects a shared environment for networked music practice on the Web.pdf:pdf},
issn = {1355-7718},
journal = {Organised Sound},
keywords = {Collaborative Performance,Networked Music Practice,Web},
mendeley-tags = {Collaborative Performance,Networked Music Practice,Web},
number = {03},
pages = {233--242},
title = {{Public Sound Objects: a shared environment for networked music practice on the Web}},
url = {http://journals.cambridge.org/abstract{\_}S135577180500097X},
volume = {10},
year = {2005}
}
@article{Hall1968,
abstract = {doi: 10.1086/200975 Virtually everything that man is and does is associated with space. Man's sense of space is a synthesis of many sensory inputs: visual, auditory, kinesthetic, olfactory, and thermal. Not only does each of these constitute a complex system (as for example, the dozen or more different ways of experiencing depth visually), but each is molded and patterned by culture. Hence people reared in different cultures live in different sensory worlds. What is more, they are generally unaware of the degree to which the worlds may differ. From the study of culture we learn that the patterning of perceptual worlds is a function not only of the specific culture but of the relationship, activity, and emotions present in a given situation. Therefore, when two people of different cultures interact, each uses different criteria to interpret the other's behavior, and each may easily misinterpret the relationship, the activity, or the emotions involved. The study of culture in the proxemic sense is the study of peoples' use of their perceptual apparatus in different emotional states during different activities, in different relationships, settings, and contexts. No single research technique is sufficient in scope to investigate this complex, multi-dimensional subject. The research technique is, therefore, a function of the particular facet under examination at the time and many call for the involvement of many disciplines. Like all basic studies of the communicative process, proxemics, as I think of it, is more concerned with how than why, and more concerned with structure than content. The work is admittedly detailed and is apt to be routine. It addresses itself to basic human situations in an area of culture that is ordinarily hidden from conscious awareness. For this reason, proxemics frequently leads to new insights about specific cultures, as well as to insights into the generalized concept of culture itself. In formulating my thinking concerning proxemics, I have maintained that culture is an extension of basic biological processes. While man's extensions as they evolve may mask the underlying relationships which maintain the equilibrium of biological systems, the relationships and systems are no less real by virtue of being hidden. In the words of Ian McHarg (1963): ...no species can exist without an environment, no species can exist in an environment of its exclusive creation, no species can survive, save as a nondisruptive member of an ecological community. Every member must adjust to other members of the community and to the environment in order to survive. Man is not excluded from this test.},
author = {Hall, Edward T. and Birdwhistell, Ray L. and Bock, Bernhard and Bohannan, Paul and Diebold,, A. Richard and Durbin, Marshall and Edmonson, Munro S. and Fischer, J. L. and Hymes, Dell and Kimball, Solon T. and {La Barre}, Weston and McClellan, J. E. and Marshall, Donald S. and Milner, G. B. and Sarles, Harvey B. and Trager, George L and Vayda, Andrew P.},
doi = {10.1086/200975},
isbn = {00113204},
issn = {0011-3204},
journal = {Current Anthropology},
number = {2/3},
pages = {83--108},
title = {{Proxemics [and Comments and Replies]}},
url = {http://www.journals.uchicago.edu/doi/10.1086/200975},
volume = {9},
year = {1968}
}
@inproceedings{Bisig2013b,
address = {Cairo},
author = {Bisig, Daniel and Kocher, Philippe},
booktitle = {Proceedings of the Consciousness Reframed Conference},
title = {{Trails II}},
year = {2013}
}
@article{Arfib2002,
abstract = {This paper is about mapping strategies between gesture data and synthesis model parameters by means of perceptual spaces. We define three layers in the mapping chain: from gesture data to gesture perceptual space, from sound perceptual space to synthesis model parameters, and between the two perceptual spaces. This approach makes the implementation highly modular. Both perceptual spaces are developed and depicted with their features. To get a simple mapping between the gesture perceptual subspace and the sound perceptual subspace, we need to focus our attention on the two other mappings. We explain the mapping types: explicit/ implicit, static/dynamic. We also present the technical and aesthetical limits introduced by mapping. Some practical examples are given of the use of perceptual spaces in experiments done at LMA in a musical context. Finally, we discuss several implications of the mapping strategies: the influence of chosen mapping limits onto performers' virtuosity, and the incidence of mapping on the learning process with virtual instruments and on improvisation possibilities.},
author = {Arfib, D. and Couturier, J M and Kessous, L and Verfaille, V},
doi = {10.1017/S1355771802002054},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Arfib et al. - 2002 - Strategies of mapping between gesture data and synthesis model parameters using perceptual spaces.pdf:pdf},
isbn = {1469-8153},
issn = {1355-7718},
journal = {Organised Sound},
number = {02},
pages = {127--144},
publisher = {Zurcher Fachhochschule},
title = {{Strategies of mapping between gesture data and synthesis model parameters using perceptual spaces}},
url = {http://journals.cambridge.org/OSO{\%}5Cnhttp://journals.cambridge.org/abstract{\_}S1355771802002054},
volume = {7},
year = {2002}
}
@phdthesis{Jorda2005,
abstract = {This is a dissertation about performing music with computers, and about constructing the tools that will facilitate playing and improvising with these computers. The primary aim of this research is to construct a theoretical framework that could serve in evaluating the potential, the possibilities and the diversity of new digital musical instruments, with the hope that these ideas may inspire and assist the construction of new and powerful instruments with which perform and listen to wonderful new and previously unheard music. Computer-based interactive music systems date back to the late 1960s, initially involving computer-controlled analog synthesizers in concerts or installations. The use of real-time algorithmic composition spread in the 1970s with the work of composers and performers such as David Behrman, Joel Chadabe, Salvatore Martirano, Gordon Mumma or Laurie Spiegel. However the most rapid period of growth probably occurred during the mid 1980s with the MIDI standardization and, subsequently, with the advent of data-flow graphical programming languages such as Max, which made the design and implementation of custom interactive systems simpler than ever before. In spite of this, nearly four decades after the works of these pioneers, the design of computer-based music instruments, and computer music performance and improvisation in general, still seem immature multidisciplinary areas in which knowledge does not behave in incremental and accumulative ways, resulting in the permanent textquoterightreinvention of the wheeltextquoteright. New digital instrument design is a broad field, encompassing highly technological areas (e.g. electronics and sensor technology, sound synthesis and processing techniques, software engineering, etc.), and disciplines related to the study of human behavior (e.g. psychology, physiology, ergonomics and human-computer interaction components, etc.). Much of this focused research attempts to solve independent parts of the problem an approach essential to achieve any progress in this field. However, as this dissertation will show, it is also clearly insufficient. I believe an approach dedicated to the integrated understanding of the whole is the key to achieving fruitful results. Integral studies and approaches, which consider not only ergonomic or technological but also psychological, philosophical, conceptual, musicological, historical and above all, musical issues, even if non-systematic by definition, are necessary for genuine progress. Putting forward the idea that a digital instrument is a conceptual whole, independent of its potential components and features (e.g. the ways it is controlled or its sonic or musical output tendencies), we will investigate the essence and the potential highlights of new digital instruments, the new musical models and the new music making paradigms they can convey. This dissertation begins with the assumption that better new musical instruments based on computers can only be conceived by exploring three parallel paths identifying the quintessence of new digital instruments; what they can bring of really original to the act of music performance; how can they redefine it; identifying the drawbacks or obsolescences of traditional instruments; what limitations or problems could be eliminated, improved or solved; without forgetting the essential generic assets of traditional instruments; those qualities that should never be forgotten nor discarded. The identification of these points is the primary aim of this thesis. There is a complex interconnected relationship between the tasks of imagining, designing and crafting musical computers, and performing and improvising with them. This relationship can only be understood as a permanent work in progress. This thesis comes from my own experience of fifteen years as a luthier-improviser. Therefore the dissertation is both theoretical (or conceptual) and experimental in approach, although the experiments it documents span years, even decades. To better organize this, the thesis is divided in three parts. Part I progressively enlightens the aforementioned three fundamental exploration paths. This is achieved by introducing the new possibilities offered by digital instruments, in addition to providing a thorough overview of current know-how and of the technical and conceptual frameworks in which new instrument designers and researchers are currently working on. Several taxonomies that will help us in developing a more synthetic and clear overview of the whole subject, are also presented. This first part concludes in chapter seven, presenting the first fundamental contribution of this dissertation; a theoretical framework for the evaluation of the expressive possibilities new digital musical instruments can offer to their performers. Part II describes in depth seven musical instruments, the implementations of my journeys into Digital Lutherie, developed during the previous decade. Since all seven are conceptually very different, each of them serves to illustrate several paradigms introduced in Part I. Presented in chronological order, these music instrument also help to clarify and understand of the path that has led me to the conception of the framework previously introduced. Part III incorporates the teachings and conclusions resulting from this evolutionary journey, and present the final milestone of this dissertation the presentation of possible solutions to better accomplish the goals presented at the end of the part I. Finally this dissertation concludes with what could be considered textquoterightmy digital lutherie decaloguetextquoteright which synthesizes most of the ideas introduced in the thesis. As a postlude, I offer the reacTable to be presented as future work. The reacTable is a digital instrument which constitutes the first one conceived from scratch, that takes into account all the concepts introduced in this thesis, the culmination thus far of my journey into Digital Lutherie},
author = {Jord{\`{a}}, Sergi},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Jord{\`{a}} - 2005 - Digital Lutherie Crafting musical computers for new musics' performance and improvisation.pdf:pdf},
school = {Universitat Pompeu Fabra},
title = {{Digital Lutherie Crafting musical computers for new musics' performance and improvisation}},
url = {http://dialnet.unirioja.es/servlet/tesis?codigo=19509},
year = {2005}
}
@article{Verstraete2005,
author = {Verstraete, Pieter},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Verstraete - 2005 - Interfacing Dance. Choreographing (by) gestural controls.pdf:pdf},
journal = {Sound Moves},
pages = {197},
title = {{Interfacing Dance. Choreographing (by) gestural controls.}},
year = {2005}
}
@article{Schiesser2012a,
abstract = {An augmented bass clarinet is developed in order to extend the performance and composition potential of the instrument. Four groups of sensors are added: key positions, inertial movement, mouth pressure and trigger switches. The instrument communicates wirelessly with a receiver setup which produces an OSC data stream, usable by any application on a host computer. The SABRe projects intention is to be neither tied to its inventors nor to one single player but to offer a reference design for a larger community of bass clarinet players and composers. For this purpose, several instruments are made available and a number of composer residencies, workshops, presentations and concerts are organized. These serve for evaluation and improvement purposes in order to build a robust and user friendly extended musical instrument, that opens new playing modalities.},
author = {Schiesser, S{\'{e}}bastien and Schacher, Jan},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Schiesser, Schacher - 2012 - SABRe The Augmented Bass Clarinet.pdf:pdf},
journal = {Proceedings of the International Conference on New Interfaces for Musical Expression},
keywords = {air pressure,augmented instrument,bass clarinet,sensors},
pages = {109--112},
title = {{SABRe : The Augmented Bass Clarinet}},
year = {2012}
}
@inproceedings{Schacher2016a,
address = {Brighton},
author = {Schacher, Jan and Bisig, Daniel},
booktitle = {Proceedings of International Conference on Live Interfaces},
pages = {80--88},
title = {{Face to Face – Performers and Algorithms in Mutual Dependency}},
year = {2016}
}
@inproceedings{Schiesser2012,
abstract = {This paper focuses on the Sensor Augmented Bass clar- inet Research (SABRe) in terms of musical practice, instrumentalist skills and compositional approaches. After a short overviewof the concept of embodiment and instrument, the new possibilities of the SABRe instrument are exposed. Then, the first realized compositions present the strategies they deploy in view of the new control modal- ities and the exploration of affordances this augmented bass clarinet offers. Finally, some possible improvements and perspectives are outlined.},
author = {Schiesser, S{\'{e}}bastien and Schacher, Jan},
booktitle = {Proceedings of the International Computer Music Conference},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Schiesser, Schacher - 2012 - SABRe AFFORDANCES , REALIZATIONS AND PERSPECTIVES.pdf:pdf},
isbn = {9780984527410},
issn = {2223-3881},
pages = {408--411},
title = {{SABRe: Affordances, realizations and perspectives}},
year = {2012}
}
@book{Gabrielli2016,
address = {Singapore},
author = {Gabrielli, Leonardo and Squartini, Stefano},
doi = {10.1007/978-981-10-0335-6},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Gabrielli, Squartini - 2016 - Wireless Networked Music Performance.pdf:pdf},
isbn = {978-981-10-0335-6},
keywords = {Distributed Performance,Networked Music Practice},
mendeley-tags = {Distributed Performance,Networked Music Practice},
publisher = {Springer},
title = {{Wireless Networked Music Performance}},
year = {2016}
}
@article{Murray-Browne2011,
abstract = {Many performers of novel musical instruments find it difficult to engage audiences beyond those in the field. Previousresearch points to a failure to balance complexity with usability, and a loss of transparency due to the detachmentof the controller and sound generator. The issue is oftenexacerbated by an audience's lack of prior exposure to theinstrument and its workings.However, we argue that there is a conflict underlyingmany novel musical instruments in that they are intendedto be both a tool for creative expression and a creative workof art in themselves, resulting in incompatible requirements.By considering the instrument, the composition and theperformance together as a whole with careful considerationof the rate of learning demanded of the audience, we propose that a lack of transparency can become an asset ratherthan a hindrance. Our approach calls for not only controllerand sound generator to be designed in sympathy with eachother, but composition, performance and physical form too.Identifying three design principles, we illustrate this approach with the Serendiptichord, a wearable instrument fordancers created by the ,$\backslash$n,$\backslash$nauthors.},
author = {Murray-Browne, Tim and Mainstone, Di and Bryan-Kinns, Nick and Plumbley, Mark D},
isbn = {0953961206},
issn = {22204806},
journal = {Proceedings of the 2011 International Conference on New Interfaces for Musical Expression (NIME2011)},
keywords = {Performance,ators or engage audiences,beyond those within the,composed instrument,constraint,constraint.,field,however,many fail to enrol,performance,performers beyond their cre-,transparency},
number = {June},
pages = {56--59},
title = {{The Medium is the Message: Composing Instruments and Performing Mappings}},
url = {http://www.nime.org/proceedings/2011/nime2011{\_}056.pdf},
year = {2011}
}
@phdthesis{Knutzen2013,
annote = {NULL},
author = {Knutzen, Hakon},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Knutzen - 2013 - Haptics in the Air - Exploring Vibrotactile Feedback for Digital Musical Instruments with Open Air Controllers.pdf:pdf},
keywords = {AHMI,DMI,feedback,open-air,vibration},
mendeley-tags = {AHMI,DMI,feedback,open-air,vibration},
number = {October},
school = {University of Oslo},
title = {{Haptics in the Air - Exploring Vibrotactile Feedback for Digital Musical Instruments with Open Air Controllers}},
year = {2013}
}
@inproceedings{Alaoui2014,
abstract = {Choreography is the art of crafting movement, developed through a long history of techniques. Like other compositional processes, choreography is a complex creative process that explores a variety of formal procedures that can result in unique artistic creations. Current computational systems for assisting choreography tend to be idiosyncratic, with emphasis on different feature sets of the compositional process (including movement, structure or expression). In this paper we examine existing technological systems for support- ing choreography and group them by their purpose: reflection, generation, real-time interaction, and annotation. We then analyze these system features using Laban Movement Analysis, a comprehensive language for movement descrip- tion, representation, expression and performance. Our paper articulates the relative benefits of these systems based on experiential aspects of choreography, and posits future directions of intelligent systems for supporting and partnering with choreography.},
author = {Alaoui, Sarah Fdili and Carlson, Kristin and Schiphorst, Thecla},
booktitle = {Proceedings of the 2014 International Workshop on Movement and Computing - MOCO '14},
doi = {10.1145/2617995.2617996},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Alaoui, Carlson, Schiphorst - 2014 - Choreography as Mediated through Compositional Tools for Movement Constructing a Historical Perspec.pdf:pdf},
isbn = {9781450328142},
keywords = {Choreography,Computational Choreographic Systems,Expression,Laban Movement Analysis,Movement},
pages = {1--6},
title = {{Choreography as Mediated through Compositional Tools for Movement: Constructing a Historical Perspective}},
url = {http://dl.acm.org/citation.cfm?id=2617995.2617996{\%}5Cnhttp://dl.acm.org/citation.cfm?doid=2617995.2617996},
year = {2014}
}
@article{Hall1963,
author = {Hall, Edward T.},
doi = {10.1525/aa.1963.65.5.02a00020},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Hall - 1963 - A System for the Notation of Proxemic Behavior.pdf:pdf},
issn = {0002-7294},
journal = {American Anthropologist},
month = {oct},
number = {5},
pages = {1003--1026},
title = {{A System for the Notation of Proxemic Behavior}},
volume = {65},
year = {1963}
}
@incollection{Gunduz2010,
abstract = {This article explores the collaboration between bodies and interactive technologies in relation to the cultural practice of contemporary dance. Aiming to counter-balance the increasing fear of disembodiment of the dancing body, it offers a phenomenological approach to examine the partner- work between physical bodies and abstract digital technologies. In addition, this paper examines the consequences of the integration of digital technologies for the existing cultural practice of dance and the roles of digital technologies incorporated in stage performances and illustrate these changes via the case study Apparition (2004).},
author = {G{\"{u}}nd{\"{u}}z, Zeynep},
booktitle = {Humanity in Cibernetic Environments},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/G{\"{u}}nd{\"{u}}z - 2010 - Interactive Dance The Merger of Media Technologies and the Dancing Body. Visions of Humanity in Cyberculture, Cyberspace.pdf:pdf},
isbn = {9781904710714},
pages = {71--82},
title = {{Interactive Dance: The Merger of Media Technologies and the Dancing Body. Visions of Humanity in Cyberculture, Cyberspace, and Science Fiction}},
url = {https://www.academia.edu/358576/Humanity{\_}in{\_}Cybernetic{\_}Environments},
year = {2010}
}
@inproceedings{Morgan2015,
archivePrefix = {arXiv},
arxivId = {9780201398298},
author = {Morgan, Evan B and Gunes, Hatice and Bryan-kinns, Nick},
booktitle = {Human-Computer Interaction – INTERACT 2015},
doi = {10.1007/978-3-319-22701-6},
eprint = {9780201398298},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Morgan, Gunes, Bryan-kinns - 2015 - Human-Computer Interaction – INTERACT 2015.pdf:pdf},
isbn = {978-3-319-22700-9},
issn = {16113349},
keywords = {eye-tracking,groupware,musical interaction,work},
pages = {47--54},
pmid = {4520227},
title = {{The LuminUs: Providing Musicians with Visual Feedback on the Gaze and Body Motion of Their Co-performers}},
url = {http://link.springer.com/10.1007/978-3-319-22701-6},
volume = {9296},
year = {2015}
}
@inproceedings{Madgewick2013b,
author = {Madgewick, Sebastian and Mitchell, Thomas},
booktitle = {SMC Sound and Music Computing Conference},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Madgwick, Mitchell - 2013 - x-OSC - A versatile wireless I O device for creative music applications.pdf.pdf:pdf},
isbn = {978-3-8325-3472-1},
title = {{x-OSC - A versatile wireless I O device for creative music applications.pdf}},
year = {2013}
}
@inproceedings{Lind2016,
abstract = {Digitalization has enabled material decoupling of sound from the physical devices traditionally used to conceive it. This paper reports an artistic exploration of novel mappings between everyday objects and digital sound. The Wheel Quintet – a novel musical instrument comprising four bicycle wheels and a skateboard – was created using off-the-shelf components and visual programming in Max / MSP. The use of everyday objects sought to enable people to quickly master the instrument, regardless of their musical backgrounds, and collectively create polytempic musical textures in a participatory art context. Applying an action research approach, the paper examines in detail two key cycles of planning, action, and analysis related to the instrument, involving an interactive museum exhibition open to the public and a concert hall performance conducted by an animated music notation system. Drawing on insights from the study, the paper contributes new knowledge concerning the creation and use of novel interfaces for music composition and performance enabled by digitalization.},
address = {Brisbane},
author = {Lind, Anders and Nyl{\'{e}}n, Daniel},
booktitle = {NIME '16},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Lind, Nyl{\'{e}}n - 2016 - Mapping Everyday Objects to Digital Materiality in The Wheel Quintet Polytempic Music and Participatory Art.pdf:pdf},
keywords = {Digital materiality,music composition and performance,participatory art,physical materiality,polytempic music},
pages = {84--89},
title = {{Mapping Everyday Objects to Digital Materiality in The Wheel Quintet : Polytempic Music and Participatory Art}},
year = {2016}
}
@article{Latulipe2011a,
abstract = {The integration of interactive technology with temporal art such as dance is an exciting, emerging area. The design space for such collaborations is immense, with variations in sensors, visualizations, and how these interact with dancers and choreography},
author = {Latulipe, Celine and Charlotte, Carolina and Carroll, Erin a and Lottridge, Danielle},
doi = {10.1145/1978942.1979209},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Latulipe et al. - 2011 - Evaluating Longitudinal Projects Combining Technology with Temporal Arts.pdf:pdf},
isbn = {9781450302678},
journal = {Conference on Human Factors in Computing Systems},
pages = {1835--1844},
title = {{Evaluating Longitudinal Projects Combining Technology with Temporal Arts}},
url = {http://portal.acm.org/citation.cfm?id=1978942.1979209{\&}coll=DL{\&}dl=ACM{\&}CFID=33968166{\&}CFTOKEN=60607906},
year = {2011}
}
@article{Shaw2015,
abstract = {In this paper we present Fields, a sound diffusion performance implemented with web technologies that run on the mobile devices of audience members. Both a technical system and bespoke composition, Fields allows for a range of sonic diffusions to occur, and therefore has the potential to open up new paradigms for spatialised music and media performances. The project introduces how handheld technology used as a collective array of speakers controlled live by a centralized performer can create alternative types of participation within musical performance. Fields not only offers a new technological approach to sound diffusion, it also provides an alternative way for audiences to participate in live events, and opens up unique forms of engagement within sonic media contexts.},
author = {Shaw, Tim and Piquemal, S{\'{e}}bastien and Bowers, John},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Shaw, Piquemal, Bowers - 2015 - Fields An Exploration into the use of Mobile Devices as a Medium for Sound Diffusion.pdf:pdf},
journal = {Proceedings of the International Conference on New Interfaces for Musical Expression},
pages = {281--284},
title = {{Fields: An Exploration into the use of Mobile Devices as a Medium for Sound Diffusion}},
url = {http://www.nime.org/proceedings/2015/nime2015{\_}196.pdf},
year = {2015}
}
@inproceedings{Baalman2010,
abstract = {SenseStage is a research-creation project to develop a wireless sensor network infrastructure for live performance and interactive, real-time environments. The project is motivated by the economic and technical constraints of live performance contexts and the lack of existing tools for artistic work with wireless sensing platforms. The development is situated within professional artistic contexts and tested in real world scenarios. In this paper we discuss our choice of wireless platform, the design of the hardware and firmware, battery options, and an evaluation of the data transmission quality within the wireless network. Additionally, software integration of the wireless platform with popular media programming environments is addressed, as well as evaluation and dissemination of the technology through workshops. Finally, we elaborate on the application of the hardware and software infrastructure in professional artistic projects: two dance performances, two media projects involving environmental data and an interactive, multi-sensory installation.},
author = {Baalman, Marije A J and Belleval, Vincent De and Salter, Christopher L and Malloch, Joseph and Thibodeau, Joseph and Wanderley, Marcelo M.},
booktitle = {Proceedings of International Computer Music Conference},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Baalman et al. - 2010 - Sense Stage - Low Cost , Open Source Wireless Sensor Infrastructure for Live Performance and Interactive , Real.pdf:pdf},
isbn = {0971319286},
pages = {242--249},
title = {{Sense / Stage - Low Cost , Open Source Wireless Sensor Infrastructure for Live Performance and Interactive , Real-Time Environments}},
year = {2010}
}
@article{Marquez-Borbon2011,
author = {Marquez-Borbon, Adnan and Gurevich, Michael and Fyans, A Cavan and Stapleton, Paul},
journal = {Proceedings of the 2011 International Conference on New Interfaces for Musical Expression (NIME2011)},
keywords = {dmis,experiment,instrument design,methodology},
number = {June},
pages = {373--376},
title = {{Designing Digital Musical Interactions in Experimental Contexts}},
url = {http://www.nime.org/proceedings/2011/nime2011{\_}373.pdf},
year = {2011}
}
@incollection{Rovan2000,
annote = {NULL},
author = {Rovan, Joseph and Hayward, Vincent},
booktitle = {Trends in Gestural Control of Music},
editor = {Wanderley, M and Battier, M},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Rovan, Hayward - 2000 - Typology of tactile sounds and their synthesis in gesture-driven computer music performance.pdf:pdf},
keywords = {AHMI,devices,haptic,musical{\_}practice,psychophysics,synthesis,touch},
mendeley-tags = {AHMI,devices,haptic,musical{\_}practice,psychophysics,synthesis,touch},
pages = {297--320},
publisher = {IRCAM},
title = {{Typology of tactile sounds and their synthesis in gesture-driven computer music performance}},
year = {2000}
}
@inproceedings{Schacher2017,
address = {Mumbai},
author = {Schacher, Jan and Bisig, Daniel},
booktitle = {Proceedings of the Interact Conference},
pages = {submitted},
title = {{Haunting Space, Social Interaction in a Large-Scale Media Environment}},
year = {2017}
}
@inproceedings{Hope2015a,
address = {Paris},
author = {Hope, Cat and Vickery, Lindsay},
booktitle = {Proceedings of the International Conference on Technologies for Music Notation and Representation},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Hope, Vickery - 2015 - The DECIBEL Scoreplayer - A Digital Tool for Reading Graphic Notation.pdf:pdf},
isbn = {978-2-9552905-0-7},
keywords = {Mobile Score,Networked Music Practice,iPad},
mendeley-tags = {Mobile Score,Networked Music Practice,iPad},
pages = {59--70},
publisher = {Institut de Recherche en Musicologie},
title = {{The DECIBEL Scoreplayer - A Digital Tool for Reading Graphic Notation}},
year = {2015}
}
@article{Newland2014,
abstract = {Existing qualitative approaches within the field of music perception and embodied music cognition provide scientific models for the evaluation of physical gestures and their expressive impact in performance. This article examines the ways in which qualitative research methodologies and outcomes may be used as stimuli for new choreographic research, drawing upon the original performance ‘Woman=Music=Desire'. Beginning with an illustrated account of expressive features of piano performance by music researchers such as Fran{\c{c}}ois Delalande and Mark Thompson, recent departures in choreographic and related artistic practice that indicate a growing interest in the expressive function of musical corporeity are discussed. Through exploring such work, the intersubjective and kinesthetic relationship occurring between musician and spectator is explored via an examination of gestural empathy. Thus, through re-appropriating instrumental gestures within practice-led research that interrogates the close relationship between corporeity and expressivity, the musician's body emerges as a dancing body with the creative potential for a new and exciting departure in choreographic practice.},
author = {Newland, Imogene},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Newland - 2014 - Instrumental gesture as choreographic practice Performative approaches to understanding corporeal expressivity in music.pdf:pdf},
journal = {Choreographic Practices},
keywords = {corporeal expressivity,instrumental gesture,intersubjectivity,kinesthetic empathy,musical body,performativity},
number = {2},
pages = {149--168},
title = {{Instrumental gesture as choreographic practice: Performative approaches to understanding corporeal expressivity in music}},
volume = {5},
year = {2014}
}
@article{Graham2015,
abstract = {This paper presents the ideas and mapping strategies behind a performance system that uses a combination of motion tracking and feature extraction tools to manage complex multichannel audio materials for real-time music composition. The use of embodied metaphors within these mappings is seen as a means of managing the complexity of a musical performance across multiple modalities. In particular, we will investigate how these mapping strategies may facilitate the creation of performance systems whose accessibility and richness are enhanced by common integrating bases. A key focus for this work is the investigation of the embodied image schema theories of Lakoff and Johnson alongside similarly embodied metaphorical models within Smalley's influential theory of electroacoustic music (spectromorphology). These metaphors will be investigated for their use as grounding structural components and dynamics for creative practices and musical interaction design. We argue that pairing metaphorical models of forces with environmental forms may have particular significance for the design of complex mappings for digital music performance.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Graham, Richard and Bridges, Brian},
doi = {10.1101/gr.075622.107},
eprint = {arXiv:1011.1669v3},
isbn = {9781450318990},
issn = {0148-9267},
journal = {Proceedings of the International Conference on New Interfaces for Musical Expression},
keywords = {embodied,feature,gesture,mapping,metaphor,schemas,spatialization,timbre,tracking},
number = {1997},
pages = {103--106},
pmid = {18417725},
title = {{Managing Musical Complexity with Embodied Metaphors}},
year = {2015}
}
@misc{Spors2013,
abstract = {This paper reviews the current state of loud- speaker-based spatial sound reproduction methods from technical perspective as well as perceptual perspective. A nomenclature is developed that allows for a strict separation between these two perspectives. The physical fundamentals, practical realization, and results from perceptual studies are discussed for a number of well-established and emerging re- production techniques. Further, the paper outlines novel ap- proaches to spatial sound evaluation in terms of perceived quality and provides a comparison of current approaches.},
author = {Spors, Sascha and Wierstorf, Hagen and Raake, Alexander and Melchior, Frank and Frank, Matthias and Zotter, Franz},
booktitle = {Proceedings of the IEEE},
doi = {10.1109/JPROC.2013.2264784},
issn = {00189219},
keywords = {Evaluation,higher order ambisonics,panning,perception,sound-field synthesis (SFS),spatial sound reproduction,wave field synthesis (WFS)},
number = {9},
pages = {1920--1938},
title = {{Spatial sound with loudspeakers and its perception: A review of the current state}},
volume = {101},
year = {2013}
}
@inproceedings{Schacher2016b,
abstract = {Relating movement to sound in an artistic context demands an understanding of the foundations of perception of both do-mains and the elaboration of techniques that effectively cre-ates a link with technical means from body to sound. This article explores the strategies necessary in interactive dance work to successfully link movement to sound processes. This is done by reducing the dimensions of the observed elements to the fundamentals and at the same time identifying target dimensions that allow the recreation of an equivalent expres-sion. A categorisation helps to elucidate those elements and characteristics that can be applied and looks at how they are perceived by the audience. The asymmetry that arises when using technical links to generate sound in interactive dance poses the question of dependency and exposes limits and challenges of using technology in this performing arts prac-tice.},
author = {Schacher, Jan C},
booktitle = {Proceedings of the 3rd International Symposium on Movement and Computing - MOCO '16},
doi = {10.1145/2948910.2948940},
file = {:C$\backslash$:/{\_}ICSTdocs/7-literature/sources/Schacher - 2016 - Moving Music.pdf:pdf},
isbn = {9781450343077},
keywords = {Author Keywords interactive dance,Miscellaneous,mapping strategies,multimodal correlations,perceptual categories,translations},
pages = {1--8},
title = {{Moving Music}},
url = {http://dl.acm.org/citation.cfm?doid=2948910.2948940},
year = {2016}
}
